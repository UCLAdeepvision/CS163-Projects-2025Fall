<!DOCTYPE html>
<html lang="en">

  <head>
    
      






    

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>2025F, UCLA CS163 Course Projects</title>

    <meta name="description" content="Course projects for UCLA CS163, Deep Learning in Compuver Vision">

    <meta content="2025F, UCLA CS163 Course Projects" property="og:site_name">
    
        <meta content="2025F, UCLA CS163 Course Projects" property="og:title">
    
    
        <meta content="website" property="og:type">
    
    
        <meta content="Course projects for UCLA CS163, Deep Learning in Compuver Vision" property="og:description">
    
    
        <meta content="/" property="og:url">
    
<!--
     -->

    <!-- 
    
     -->

    <link rel="shortcut icon" href="/CS163-Projects-2025Fall/assets/ucla_ico.jpg">
    <link rel="stylesheet" href="/CS163-Projects-2025Fall/assets/css/main.css">
    <link rel="canonical" href="/CS163-Projects-2025Fall/">

    <!-- For Latex -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

    <!-- Google Analytics -->
    <!-- <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-8161570-6', 'auto');
        ga('send', 'pageview');
    </script> -->

    <!-- For Facebook share button -->
    <!-- <div id="fb-root"></div>
    <script>
      (function(d, s, id) {
        var js, fjs = d.getElementsByTagName(s)[0];
        if (d.getElementById(id)) return;
        js = d.createElement(s); js.id = id;
        js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.9";
        fjs.parentNode.insertBefore(js, fjs);
      }(document, 'script', 'facebook-jssdk'));
    </script> -->

    <!-- Twitter cards -->
    <!-- <meta name="twitter:site"    content="@">
    <meta name="twitter:creator" content="@UCLAdeepvision">
    <meta name="twitter:title"   content="">

    
        <meta name="twitter:description" content="Course projects for UCLA CS163, Deep Learning in Compuver Vision">
    

    
        <meta name="twitter:card"  content="summary">
        <meta name="twitter:image" content="">
     -->
    <!-- end of Twitter cards -->

</head>


  <body>

    <header class="site-header" role="banner" id='header-bar'>

    <div class="wrapper">
        
        <a class="site-title" style="color:#F2A900" href="/CS163-Projects-2025Fall/">2025F, UCLA CS163 Course Projects  </a>

        <!-- <nav class="site-nav">
            <a class="page-link" href="http://lilianweng.github.io" target="_blank">&#x1f349; About</a>
        </nav> -->
        <nav class="site-nav">
            <a class="page-link" style="color:#F2A900" href="/CS163-Projects-2025Fall/about.html"> About</a>
        </nav>

        <nav class="site-nav">
            <a class="page-link" style="color:#F2A900" href="/CS163-Projects-2025Fall/archive.html"> Archive</a>
        </nav>


        <!-- <nav class="site-nav">
            <a class="page-link" style="color:#FFD100" href="/CS163-Projects-2025Fall/FAQ.html"> FAQ</a>
        </nav> -->
        <!-- <nav class="site-nav">
            <a class="page-link" href="/CS163-Projects-2025Fall/log.html">&#x231b; Log</a>
        </nav> -->


    </div>

</header>


    <!-- Back to top button -->
    <script src="/CS163-Projects-2025Fall/assets/vanilla-back-to-top.min.js"></script>
    <script>addBackToTop()</script>

    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="home other-pages">
  <ul class="post-list">
    
    <li>
      
      <span class="post-meta">
        Anirudh Kannan on Dec 13, 2025
        <span>
          
        </span>
      </span>

      <h2>
        <a class="post-link" href="/CS163-Projects-2025Fall/2025/12/13/team50-control-from-vision.html">Representation and Prediction for Generalizable Robot Control</a>
        
        <blockquote>
  <p>Vision-based learning has become a central paradigm for enabling robots to operate in complex, unstructured environments. Rather than relying on hand-engineered perception pipelines or task-specific supervision, recent work increasingly leverages large-scale video data to learn transferable visual representations and predictive models for control. This survey reviews a sequence of recent approaches that illustrate this progression: learning control directly from video demonstrations, pretraining universal visual representations, incorporating predictive dynamics through visual point tracking, and augmenting learning with synthetic visual data. Together, these works highlight how representation learning and prediction from video are enabling increasingly generalizable robot manipulation capabilities.</p>
</blockquote>


        
      </h2>
    </li>
    
    <li>
      
      <span class="post-meta">
        Anthony Yu on Dec 13, 2025
        <span>
          
        </span>
      </span>

      <h2>
        <a class="post-link" href="/CS163-Projects-2025Fall/2025/12/13/team48-efficient-super-resolution.html">Efficient Super-Resolution: Bridging Quality and Computation</a>
        
        <blockquote>
  <p>Super-resolution has long faced a fundamental tension: the highest-quality models require billions of operations, while edge devices demand sub-100ms inference. This article examines three recent methods—SPAN, EFDN, and DSCLoRa—that challenge this tradeoff through architectural innovation, training-time tricks, and efficient adaptation. We’ll see how rethinking the upsampling operation, leveraging structural reparameterization, and applying low-rank decomposition can each dramatically improve efficiency without sacrificing output quality.</p>
</blockquote>


        
      </h2>
    </li>
    
    <li>
      
      <span class="post-meta">
        Abdallah Fares, Dean Ali, Olana Abraham on Dec 13, 2025
        <span>
          
        </span>
      </span>

      <h2>
        <a class="post-link" href="/CS163-Projects-2025Fall/2025/12/13/team23-mask-sam.html">From Labeling to Prompting: The Paradigm Shift in Image Segmentation</a>
        
        <blockquote>
  <p>The evolution from Mask R-CNN to SAM represents a paradigm shift in computer vision segmentation, moving from supervised specialists constrained by fixed vocabularies to promptable generalists that operate class-agnostically. We examine the technical innovations that distinguish these approaches, including SAM’s decoupling of spatial localization from semantic classification and its ambiguity-aware prediction mechanism, alongside future directions in image segmentation.</p>
</blockquote>


        
      </h2>
    </li>
    
    <li>
      
      <span class="post-meta">
         on Dec 13, 2025
        <span>
          
        </span>
      </span>

      <h2>
        <a class="post-link" href="/CS163-Projects-2025Fall/2025/12/13/team22-visuomotor-policy.html">Visuomotor Policy</a>
        
        <blockquote>
  <p>Visuomotor Policy Learning studies how an agent can map high-dimensional visual observations (e.g., camera images) to motor commands in order to solve sequential decision-making tasks. In this project, we focus on settings motivated by autonomous driving and robotic manipulation, and survey modern learning-based approaches—primarily imitation learning (IL) and reinforcement learning (RL)—with an emphasis on methods that improve sample efficiency through policy/representation pretraining.</p>
</blockquote>


        
      </h2>
    </li>
    
    <li>
      
      <span class="post-meta">
        Brian Liu on Dec 13, 2025
        <span>
          
        </span>
      </span>

      <h2>
        <a class="post-link" href="/CS163-Projects-2025Fall/2025/12/13/team05-vision-language-action-models.html">Vision Language Action Models for Robotics</a>
        
        <blockquote>
  <p>The core of computer vision for robotics is utilizing deep learning to allow robots to perceive, understand, and interact with the physical world. This report explores Vision Language Action (VLA) models that combine visual input, language instruction, and robot actions in end-to-end architectures.</p>
</blockquote>


        
      </h2>
    </li>
    
    <li>
      
      <span class="post-meta">
        Lina Lee on Dec 12, 2025
        <span>
          
        </span>
      </span>

      <h2>
        <a class="post-link" href="/CS163-Projects-2025Fall/2025/12/12/team31-human-pose-estimation.html">Human Pose Estimation</a>
        
        <blockquote>
  <p>In this paper, I will be discussing the fundamentals and workings of deep learning for human pose estimation. I believe that there has been a lot of research and breakthroughs, especially recently, on technology that relates to this, and I hope that this deep dive will bring some clarity and new information to how it works!</p>
</blockquote>


        
      </h2>
    </li>
    
    <li>
      
      <span class="post-meta">
        Group 28 on Dec 7, 2025
        <span>
          
        </span>
      </span>

      <h2>
        <a class="post-link" href="/CS163-Projects-2025Fall/2025/12/07/team28-camera-pose-estimation.html">Camera Pose Estimation</a>
        
        <blockquote>
  <p>Camera pose estimation is a fundamental Computer Vision task that aims to determine the position and orientation of a camera relative to a scene using image or video data. Our project evaluates three camera pose estimation methods, COLMAP, VGGSfM, and depth-based pose estimation with ICP.</p>
</blockquote>


        
      </h2>
    </li>
    
    <li>
      
      <span class="post-meta">
        UCLAdeepvision on Jan 1, 2024
        <span>
          
        </span>
      </span>

      <h2>
        <a class="post-link" href="/CS163-Projects-2025Fall/2024/01/01/team00-instruction-to-post.html">Post Template</a>
        
        <blockquote>
  <p>[Project Track: Project N] This block is a brief introduction of your project. You can put your abstract here or any headers you want the readers to know.</p>
</blockquote>


        
      </h2>
    </li>
    
  </ul>
</div>
      </div>
    </main>

    <div style="clear: both;" />
<footer class="site-footer">
    2024 &copy; by UCLAdeepvision. All Rights Reserved. Built by <a href="https://jekyllrb.com/"
        target="_blank">Jekyll</a>

    <!-- <p>
        <a href="/CS163-Projects-2025Fall/feed.xml" target="_blank">
            <img src="/CS163-Projects-2025Fall/assets/images/logo_rss.png" />
        </a>
        <a href="https://scholar.google.com/citations?user=dCa-pW8AAAAJ&hl=en&oi=ao" target="_blank">
            <img src="/CS163-Projects-2025Fall/assets/images/logo_scholar.png" />
        </a>
        <a href="https://github.com/lilianweng" target="_blank">
            <img src="/CS163-Projects-2025Fall/assets/images/logo_github.png" />
        </a>
    </p> -->
</footer>

  </body>

</html>
