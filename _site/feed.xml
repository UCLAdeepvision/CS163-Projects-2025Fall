<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="http://localhost:4000/CS163-Projects-2025Fall/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/CS163-Projects-2025Fall/" rel="alternate" type="text/html" /><updated>2025-12-13T15:29:15-08:00</updated><id>http://localhost:4000/CS163-Projects-2025Fall/feed.xml</id><title type="html">2025F, UCLA CS163 Course Projects</title><subtitle>Course projects for UCLA CS163, Deep Learning in Compuver Vision</subtitle><author><name>UCLAdeepvision</name></author><entry><title type="html">Multimodal Trajectory Prediction</title><link href="http://localhost:4000/CS163-Projects-2025Fall/2025/12/01/team36-trajectory-prediction.html" rel="alternate" type="text/html" title="Multimodal Trajectory Prediction" /><published>2025-12-01T00:00:00-08:00</published><updated>2025-12-01T00:00:00-08:00</updated><id>http://localhost:4000/CS163-Projects-2025Fall/2025/12/01/team36-trajectory-prediction</id><content type="html" xml:base="http://localhost:4000/CS163-Projects-2025Fall/2025/12/01/team36-trajectory-prediction.html"><![CDATA[<div style="flex: 1 1 45%; min-width: 300px; text-align: center;">
    <img src="/CS163-Projects-2025Fall/assets/images/team36/scene_1679_multimodal.gif" alt="Scene 1679 Multimodal Prediction" style="width: 100%; border: 1px solid #ccc; border-radius: 5px;" />
    <p><em>My 2 models predictions on scene 1679 from L5Kit</em></p>
</div>

<blockquote>
  <p><strong>Abstract</strong><br />
Predicting the future trajectories of surrounding agents is a fundamental challenge in autonomous driving systems. In this project, I explore deep learning-based trajectory prediction using the Lyft Level-5 Motion Prediction dataset. I develop 2 models, a ResNet-based raster trajectory regressor, and a <strong>multimodal raster + agent-history fusion model</strong> capable of producing six future trajectory hypotheses with associated confidence scores. The final model achieves significant performance improvements in ADE, FDE, and Miss Rate metrics while producing interpretable, multimodal predictions essential for safe autonomous navigation.</p>
</blockquote>

<!--more-->

<ul class="table-of-content" id="markdown-toc">
  <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a>    <ul>
      <li><a href="#the-challenge-of-motion-prediction" id="markdown-toc-the-challenge-of-motion-prediction">The Challenge of Motion Prediction</a></li>
      <li><a href="#my-approach" id="markdown-toc-my-approach">My Approach</a></li>
    </ul>
  </li>
  <li><a href="#dataset--problem-formulation" id="markdown-toc-dataset--problem-formulation">Dataset &amp; Problem Formulation</a>    <ul>
      <li><a href="#the-lyft-level-5-motion-prediction-dataset" id="markdown-toc-the-lyft-level-5-motion-prediction-dataset">The Lyft Level-5 Motion Prediction Dataset</a></li>
      <li><a href="#mathematical-problem-formulation" id="markdown-toc-mathematical-problem-formulation">Mathematical Problem Formulation</a></li>
      <li><a href="#evaluation-metrics" id="markdown-toc-evaluation-metrics">Evaluation Metrics</a></li>
      <li><a href="#multimodal-specific-metrics" id="markdown-toc-multimodal-specific-metrics">Multimodal-Specific Metrics</a></li>
    </ul>
  </li>
  <li><a href="#baseline-models" id="markdown-toc-baseline-models">Baseline Models</a>    <ul>
      <li><a href="#constant-velocity-cv-baseline" id="markdown-toc-constant-velocity-cv-baseline">Constant Velocity (CV) Baseline</a></li>
      <li><a href="#constant-acceleration-ca-baseline" id="markdown-toc-constant-acceleration-ca-baseline">Constant Acceleration (CA) Baseline</a></li>
      <li><a href="#mlp-baseline" id="markdown-toc-mlp-baseline">MLP Baseline</a></li>
    </ul>
  </li>
  <li><a href="#resnet-single-trajectory-model" id="markdown-toc-resnet-single-trajectory-model">ResNet Single-Trajectory Model</a>    <ul>
      <li><a href="#motivation" id="markdown-toc-motivation">Motivation</a></li>
      <li><a href="#architecture-design" id="markdown-toc-architecture-design">Architecture Design</a></li>
      <li><a href="#loss-function-with-temporal-weighting" id="markdown-toc-loss-function-with-temporal-weighting">Loss Function with Temporal Weighting</a></li>
      <li><a href="#training-configuration" id="markdown-toc-training-configuration">Training Configuration</a></li>
    </ul>
  </li>
  <li><a href="#multimodal-raster--agent-history-model" id="markdown-toc-multimodal-raster--agent-history-model">Multimodal Raster + Agent History Model</a>    <ul>
      <li><a href="#visualization-compatibility-wrapper" id="markdown-toc-visualization-compatibility-wrapper">Visualization Compatibility Wrapper</a></li>
      <li><a href="#the-need-for-multimodality" id="markdown-toc-the-need-for-multimodality">The Need for Multimodality</a></li>
    </ul>
  </li>
  <li><a href="#model-and-design-rationale" id="markdown-toc-model-and-design-rationale">Model and Design Rationale</a>    <ul>
      <li><a href="#architecture-overview" id="markdown-toc-architecture-overview">Architecture Overview</a></li>
      <li><a href="#detailed-architecture-implementation" id="markdown-toc-detailed-architecture-implementation">Detailed Architecture Implementation</a></li>
    </ul>
  </li>
  <li><a href="#data-pipeline" id="markdown-toc-data-pipeline">Data Pipeline</a></li>
  <li><a href="#loss-function-derivation" id="markdown-toc-loss-function-derivation">Loss Function Derivation</a>    <ul>
      <li><a href="#the-challenge-of-multimodal-learning" id="markdown-toc-the-challenge-of-multimodal-learning">The Challenge of Multimodal Learning</a></li>
      <li><a href="#soft-winner-takes-all-loss" id="markdown-toc-soft-winner-takes-all-loss">Soft Winner-Takes-All Loss</a></li>
    </ul>
  </li>
  <li><a href="#training-procedure" id="markdown-toc-training-procedure">Training Procedure</a>    <ul>
      <li><a href="#training-configuration-1" id="markdown-toc-training-configuration-1">Training Configuration</a></li>
      <li><a href="#training-loop-with-mixed-precision" id="markdown-toc-training-loop-with-mixed-precision">Training Loop with Mixed Precision</a></li>
      <li><a href="#training-metrics-summary" id="markdown-toc-training-metrics-summary">Training Metrics Summary</a></li>
    </ul>
  </li>
  <li><a href="#quantitative-results" id="markdown-toc-quantitative-results">Quantitative Results</a>    <ul>
      <li><a href="#final-model-comparison" id="markdown-toc-final-model-comparison">Final Model Comparison</a></li>
      <li><a href="#multimodal-model-detailed-metrics" id="markdown-toc-multimodal-model-detailed-metrics">Multimodal Model Detailed Metrics</a></li>
      <li><a href="#trajectory-behavior-analysis" id="markdown-toc-trajectory-behavior-analysis">Trajectory Behavior Analysis</a></li>
      <li><a href="#analysis" id="markdown-toc-analysis">Analysis</a></li>
      <li><a href="#trajectory-type-breakdown" id="markdown-toc-trajectory-type-breakdown">Trajectory Type Breakdown</a></li>
      <li><a href="#oracle-performance-gap" id="markdown-toc-oracle-performance-gap">Oracle Performance Gap</a></li>
    </ul>
  </li>
  <li><a href="#inference-utilities" id="markdown-toc-inference-utilities">Inference Utilities</a>    <ul>
      <li><a href="#building-raster-batches-for-inference" id="markdown-toc-building-raster-batches-for-inference">Building Raster Batches for Inference</a></li>
      <li><a href="#extracting-all-mode-predictions" id="markdown-toc-extracting-all-mode-predictions">Extracting All Mode Predictions</a></li>
      <li><a href="#trajectory-distance-trimming" id="markdown-toc-trajectory-distance-trimming">Trajectory Distance Trimming</a></li>
    </ul>
  </li>
  <li><a href="#qualitative-visualizations" id="markdown-toc-qualitative-visualizations">Qualitative Visualizations</a>    <ul>
      <li><a href="#resnet-vs-multimodal-comparison" id="markdown-toc-resnet-vs-multimodal-comparison">ResNet vs Multimodal Comparison</a></li>
      <li><a href="#high-uncertainty-intersection-example" id="markdown-toc-high-uncertainty-intersection-example">High-Uncertainty Intersection Example</a></li>
      <li><a href="#high-uncertainty-intersection-from-model" id="markdown-toc-high-uncertainty-intersection-from-model">High-Uncertainty Intersection from Model</a></li>
      <li><a href="#animated-trajectory" id="markdown-toc-animated-trajectory">Animated Trajectory</a></li>
    </ul>
  </li>
  <li><a href="#discussion" id="markdown-toc-discussion">Discussion</a>    <ul>
      <li><a href="#lessons-learned" id="markdown-toc-lessons-learned">Lessons learned</a></li>
      <li><a href="#limitations" id="markdown-toc-limitations">Limitations</a></li>
      <li><a href="#potential-improvements" id="markdown-toc-potential-improvements">Potential Improvements</a></li>
    </ul>
  </li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
  <li><a href="#code-repository" id="markdown-toc-code-repository">Code Repository</a></li>
  <li><a href="#references" id="markdown-toc-references">References</a></li>
  <li><a href="#acknowledgments" id="markdown-toc-acknowledgments">Acknowledgments</a></li>
</ul>

<hr />

<h2 id="introduction">Introduction</h2>

<div style="flex: 1 1 45%; min-width: 300px; text-align: center;">
    <img src="/CS163-Projects-2025Fall/assets/images/team36/scene_12138_multimodal.gif" alt="Scene 12138 Multimodal Prediction" style="width: 100%; border: 1px solid #ccc; border-radius: 5px;" />
    <p><em>Scene 12138 from L5Kit: Comparison in a straight line.</em></p>
  </div>

<h3 id="the-challenge-of-motion-prediction">The Challenge of Motion Prediction</h3>

<p>Predicting the future motion of surrounding agents (vehicles, pedestrians, and cyclists) is one of the most critical challenges in autonomous driving. Unlike traditional robotics problems with deterministic outcomes, motion prediction in driving scenarios is inherently <strong>multimodal</strong>: a vehicle approaching an intersection might turn left, turn right, go straight, or stop, whereas a pedestrian can do those and also something completely unpredictable like jumping on your car. A robust prediction system must capture this uncertainty rather than committing to a single deterministic future.</p>

<p>The key challenges in trajectory prediction include:</p>

<ol>
  <li><strong>Multimodality</strong>: Agents can take multiple plausible paths</li>
  <li><strong>Scene Context</strong>: Road geometry, lane markings, and traffic rules constrain possible futures</li>
  <li><strong>Agent Interactions</strong>: Surrounding vehicles influence each other’s behavior</li>
</ol>

<h3 id="my-approach">My Approach</h3>

<p>I start with building models of increasing complexity to address these challenges:</p>

<ol>
  <li><strong>Kinematic Baselines</strong></li>
  <li><strong>MLP Baseline</strong></li>
  <li><strong>ResNet Single-Trajectory Model</strong></li>
  <li><strong>Multimodal Raster + History Fusion Model</strong></li>
</ol>

<hr />
<h2 id="dataset--problem-formulation">Dataset &amp; Problem Formulation</h2>

<h3 id="the-lyft-level-5-motion-prediction-dataset">The Lyft Level-5 Motion Prediction Dataset</h3>

<p>I will use the <strong>Lyft Level-5 Motion Prediction Dataset</strong>, one of the largest publicly available datasets for autonomous vehicle motion prediction. This dataset includes scenes (driving episodes), frames (ego poses over time), tracked agents with positions, orientations, bounding boxes, label probabilities, and traffic light faces, all stored in <code class="language-plaintext highlighter-rouge">.zarr</code> format, along with BEV-ready map assets (<code class="language-plaintext highlighter-rouge">aerial_map</code>, <code class="language-plaintext highlighter-rouge">semantic_map</code>), train/validate/test splits (<code class="language-plaintext highlighter-rouge">train.zarr</code>, <code class="language-plaintext highlighter-rouge">validate.zarr</code>, <code class="language-plaintext highlighter-rouge">test.csv</code>, <code class="language-plaintext highlighter-rouge">mask.npz</code>), and an optional larger training set (<code class="language-plaintext highlighter-rouge">train_full.csv</code>).<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup></p>

<h3 id="mathematical-problem-formulation">Mathematical Problem Formulation</h3>

<p>Given:</p>
<ul>
  <li>Agent history positions: \(\mathbf{H} = \{(x_t, y_t)\}_{t=-T_h}^{0}\) where \(T_h = 10\) frames</li>
  <li>Rasterized scene context: \(\mathbf{I} \in \mathbb{R}^{C \times H \times W}\) (semantic/satellite map)</li>
  <li>Agent availability mask: \(\mathbf{a}^h \in \{0,1\}^{T_h}\)</li>
</ul>

<p>Predict:</p>
<ul>
  <li>Future trajectory: \(\hat{\mathbf{Y}} = \{(\hat{x}_t, \hat{y}_t)\}_{t=1}^{T_f}\) where \(T_f = 50\) frames</li>
</ul>

<p>For multimodal prediction, \(M\) trajectory hypotheses with associated confidences can be calculated with:</p>
<ul>
  <li>Trajectories: \(\{\hat{\mathbf{Y}}^{(m)}\}_{m=1}^{M}\) where \(M = 6\)</li>
  <li>Confidences: \(\{c^{(m)}\}_{m=1}^{M}\) where \(\sum_m c^{(m)} = 1\)</li>
</ul>

<h3 id="evaluation-metrics">Evaluation Metrics</h3>

<p>All models are evaluated using three standard metrics implemented in the evaluation module:</p>

<h4 id="average-displacement-error-ade"><strong>Average Displacement Error (ADE)</strong></h4>
<p>ADE measures the mean L2 distance between predicted and ground-truth positions over all valid future timesteps:</p>

\[\text{ADE} = \frac{1}{T_f} \sum_{t=1}^{T_f} \left\|\hat{\mathbf{y}}_t - \mathbf{y}_t\right\|_2\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">compute_ade</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">gt</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
    <span class="s">"""
    ADE = mean L2 distance over all valid future timesteps.
    """</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">_to_numpy</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
    <span class="n">gt</span> <span class="o">=</span> <span class="n">_to_numpy</span><span class="p">(</span><span class="n">gt</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">_to_numpy</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>

    <span class="n">diff</span> <span class="o">=</span> <span class="n">pred</span> <span class="o">-</span> <span class="n">gt</span>                      <span class="c1"># (N, T, 2)
</span>    <span class="n">dist</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (N, T)
</span>
    <span class="n">num</span> <span class="o">=</span> <span class="p">(</span><span class="n">dist</span> <span class="o">*</span> <span class="n">mask</span><span class="p">).</span><span class="nb">sum</span><span class="p">()</span>             <span class="c1"># sum of valid distances
</span>    <span class="n">den</span> <span class="o">=</span> <span class="n">mask</span><span class="p">.</span><span class="nb">sum</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-8</span>               <span class="c1"># count of valid steps
</span>    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">num</span> <span class="o">/</span> <span class="n">den</span><span class="p">)</span>
</code></pre></div></div>
<p>This computes exactly what the formula expresses: take the L2 distance at each timestep, filter out padded frames using the mask, and average over all valid predictions.</p>

<h4 id="final-displacement-error-fde"><strong>Final Displacement Error (FDE)</strong></h4>

<p>FDE measures how far off the prediction is at the final valid timestep:</p>

\[\text{FDE} = \left\|\hat{\mathbf{y}}_{T_f} - \mathbf{y}_{T_f}\right\|_2\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">compute_fde</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">gt</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
    <span class="s">"""
    FDE = mean L2 distance at the final valid timestep for each sample.
    """</span>
    <span class="n">pred</span><span class="p">,</span> <span class="n">gt</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="n">_to_numpy</span><span class="p">(</span><span class="n">pred</span><span class="p">),</span> <span class="n">_to_numpy</span><span class="p">(</span><span class="n">gt</span><span class="p">),</span> <span class="n">_to_numpy</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
    <span class="n">fdes</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">)):</span>
        <span class="n">valid_idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">mask</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_idx</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">valid_idx</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>                 <span class="c1"># final valid timestep
</span>        <span class="n">diff</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">-</span> <span class="n">gt</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span>
        <span class="n">fdes</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff</span><span class="p">))</span>

    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">fdes</span><span class="p">))</span> <span class="k">if</span> <span class="n">fdes</span> <span class="k">else</span> <span class="mf">0.0</span>
</code></pre></div></div>

<h4 id="miss-rate--2m-mr2m"><strong>Miss Rate @ 2m (MR@2m)</strong></h4>

<p>A trajectory is counted as a miss if its final predicted point is more than 2 meters away from the ground truth:</p>

\[\text{MR@2m} = \frac{1}{N} \sum_{i=1}^{N} \mathbf{1}\left[\text{FDE}_i &gt; 2.0\right]\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">compute_miss_rate</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">gt</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">2.0</span><span class="p">):</span>
    <span class="s">"""
    Miss rate = fraction of trajectories whose final position error &gt; threshold.
    """</span>
    <span class="n">pred</span><span class="p">,</span> <span class="n">gt</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="n">_to_numpy</span><span class="p">(</span><span class="n">pred</span><span class="p">),</span> <span class="n">_to_numpy</span><span class="p">(</span><span class="n">gt</span><span class="p">),</span> <span class="n">_to_numpy</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
    <span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">pred</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">misses</span><span class="p">,</span> <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">valid_idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">mask</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_idx</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">valid_idx</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">err</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">pred</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">-</span> <span class="n">gt</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">])</span>
        <span class="n">misses</span> <span class="o">+=</span> <span class="p">(</span><span class="n">err</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">misses</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span> <span class="k">if</span> <span class="n">total</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">0.0</span>
</code></pre></div></div>

<hr />

<h3 id="multimodal-specific-metrics">Multimodal-Specific Metrics</h3>

<p>When evaluating multimodal predictors, standard metrics like ADE and FDE only tell part of the story. If I select the model’s most confident prediction and measure its error, I’m testing both trajectory quality <em>and</em> confidence calibration simultaneously. To disentangle these, I introduce oracle metrics that measure the best-case performance across all modes, plus calibration metrics that evaluate how well the model knows which mode to trust.</p>

<h4 id="minimum-ade-minade"><strong>Minimum ADE (minADE)</strong></h4>

<p>Instead of using the model’s confidence to select a mode, minADE asks: “If an oracle picked the best mode for each sample, how accurate would the predictions be?” This reveals the model’s trajectory generation quality independent of its confidence head:</p>

<p>\(\text{minADE} = \frac{1}{N} \sum_{i=1}^{N} \min_{m \in [1,M]} \left( \frac{1}{T_f} \sum_{t=1}^{T_f} \left\|\hat{\mathbf{y}}_{i,t}^{(m)} - \mathbf{y}_{i,t}\right\|_2 \right)\)</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">compute_min_ade</span><span class="p">(</span><span class="n">trajs</span><span class="p">,</span> <span class="n">gt</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
    <span class="s">"""
    Oracle minADE: selects the best mode per sample based on actual error.
    
    trajs: (N, M, T, 2) - M trajectory hypotheses per sample
    gt:    (N, T, 2)    - ground truth trajectories
    mask:  (N, T)       - validity mask
    
    Returns: float - average of per-sample minimum ADEs
    """</span>
    <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">trajs</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">gt_exp</span> <span class="o">=</span> <span class="n">gt</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="n">expand_as</span><span class="p">(</span><span class="n">trajs</span><span class="p">)</span>          <span class="c1"># (N, M, T, 2)
</span>    <span class="n">mask_exp</span> <span class="o">=</span> <span class="n">mask</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="n">expand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>       <span class="c1"># (N, M, T)
</span>    
    <span class="n">diff</span> <span class="o">=</span> <span class="n">trajs</span> <span class="o">-</span> <span class="n">gt_exp</span>
    <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">mask_exp</span>         <span class="c1"># (N, M, T)
</span>    
    <span class="c1"># ADE per mode: average displacement over valid timesteps
</span>    <span class="n">ade_per_mode</span> <span class="o">=</span> <span class="n">dist</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">mask_exp</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (N, M)
</span>    
    <span class="c1"># Select minimum across modes for each sample
</span>    <span class="k">return</span> <span class="n">ade_per_mode</span><span class="p">.</span><span class="nb">min</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="n">mean</span><span class="p">().</span><span class="n">item</span><span class="p">()</span>
</code></pre></div></div>

<p>The gap between standard ADE (using confidence-selected mode) and minADE reveals how much performance is lost due to imperfect confidence calibration. A large gap suggests the model generates good trajectories but struggles to identify which one is best.</p>

<h4 id="minimum-fde-minfde"><strong>Minimum FDE (minFDE)</strong></h4>

<p>Similarly, minFDE measures the oracle final displacement:</p>

<p>\(\text{minFDE} = \frac{1}{N} \sum_{i=1}^{N} \min_{m \in [1,M]} \left\|\hat{\mathbf{y}}_{i,T_f}^{(m)} - \mathbf{y}_{i,T_f}\right\|_2\)</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">compute_min_fde</span><span class="p">(</span><span class="n">trajs</span><span class="p">,</span> <span class="n">gt</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
    <span class="s">"""
    Oracle minFDE: best mode's final displacement error.
    
    For each sample, finds the mode with smallest final position error,
    regardless of what the confidence head predicted.
    """</span>
    <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">trajs</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">valid_counts</span> <span class="o">=</span> <span class="n">mask</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="nb">long</span><span class="p">()</span>
    <span class="n">last_idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">valid_counts</span> <span class="o">-</span> <span class="mi">1</span><span class="p">).</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>          <span class="c1"># (N,)
</span>    
    <span class="n">gt_final</span> <span class="o">=</span> <span class="n">gt</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">),</span> <span class="n">last_idx</span><span class="p">]</span>            <span class="c1"># (N, 2)
</span>    
    <span class="c1"># Compute FDE for each mode
</span>    <span class="n">fde_per_mode</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
        <span class="n">pred_final</span> <span class="o">=</span> <span class="n">trajs</span><span class="p">[:,</span> <span class="n">m</span><span class="p">][</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">),</span> <span class="n">last_idx</span><span class="p">]</span>  <span class="c1"># (N, 2)
</span>        <span class="n">fde_per_mode</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">pred_final</span> <span class="o">-</span> <span class="n">gt_final</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
    
    <span class="n">fde_per_mode</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">stack</span><span class="p">(</span><span class="n">fde_per_mode</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>     <span class="c1"># (N, M)
</span>    <span class="k">return</span> <span class="n">fde_per_mode</span><span class="p">.</span><span class="nb">min</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="n">mean</span><span class="p">().</span><span class="n">item</span><span class="p">()</span>
</code></pre></div></div>

<h4 id="minimum-miss-rate-minmr2m"><strong>Minimum Miss Rate (minMR@2m)</strong></h4>

<p>The oracle version of miss rate—what fraction of trajectories would miss even with perfect mode selection:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">compute_min_mr</span><span class="p">(</span><span class="n">trajs</span><span class="p">,</span> <span class="n">gt</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">2.0</span><span class="p">):</span>
    <span class="s">"""
    Oracle miss rate: fraction of samples where even the best mode
    has final displacement error &gt; threshold.
    """</span>
    <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">trajs</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">valid_counts</span> <span class="o">=</span> <span class="n">mask</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="nb">long</span><span class="p">()</span>
    <span class="n">last_idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">valid_counts</span> <span class="o">-</span> <span class="mi">1</span><span class="p">).</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="n">gt_final</span> <span class="o">=</span> <span class="n">gt</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">),</span> <span class="n">last_idx</span><span class="p">]</span>
    
    <span class="n">fde_per_mode</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
        <span class="n">pred_final</span> <span class="o">=</span> <span class="n">trajs</span><span class="p">[:,</span> <span class="n">m</span><span class="p">][</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">),</span> <span class="n">last_idx</span><span class="p">]</span>
        <span class="n">fde_per_mode</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">pred_final</span> <span class="o">-</span> <span class="n">gt_final</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
    
    <span class="n">fde_per_mode</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">stack</span><span class="p">(</span><span class="n">fde_per_mode</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">min_fde</span> <span class="o">=</span> <span class="n">fde_per_mode</span><span class="p">.</span><span class="nb">min</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>               <span class="c1"># (N,)
</span>    
    <span class="k">return</span> <span class="p">(</span><span class="n">min_fde</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">).</span><span class="nb">float</span><span class="p">().</span><span class="n">mean</span><span class="p">().</span><span class="n">item</span><span class="p">()</span>
</code></pre></div></div>

<h4 id="confidence-accuracy"><strong>Confidence Accuracy</strong></h4>

<p>This metric directly measures how often the model’s most confident mode is actually the best mode. It answers: “When the model says ‘I think mode 3 is most likely,’ how often is mode 3 actually closest to ground truth?”</p>

<p>\(\text{Conf Acc} = \frac{1}{N} \sum_{i=1}^{N} \mathbf{1}\left[\arg\max_m c_i^{(m)} = \arg\min_m E_i^{(m)}\right]\)</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">compute_conf_accuracy</span><span class="p">(</span><span class="n">trajs</span><span class="p">,</span> <span class="n">confs</span><span class="p">,</span> <span class="n">gt</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
    <span class="s">"""
    Confidence accuracy: fraction of samples where the highest-confidence
    mode is also the mode with lowest ADE.
    
    A perfect confidence head would achieve 100%. Random guessing with
    M=6 modes would achieve ~16.7%.
    """</span>
    <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">trajs</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">gt_exp</span> <span class="o">=</span> <span class="n">gt</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="n">expand_as</span><span class="p">(</span><span class="n">trajs</span><span class="p">)</span>
    <span class="n">mask_exp</span> <span class="o">=</span> <span class="n">mask</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="n">expand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>
    
    <span class="n">diff</span> <span class="o">=</span> <span class="n">trajs</span> <span class="o">-</span> <span class="n">gt_exp</span>
    <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">mask_exp</span>
    <span class="n">ade_per_mode</span> <span class="o">=</span> <span class="n">dist</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">mask_exp</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="n">best_mode_by_error</span> <span class="o">=</span> <span class="n">ade_per_mode</span><span class="p">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>    <span class="c1"># (N,) - which mode was actually best
</span>    <span class="n">best_mode_by_conf</span> <span class="o">=</span> <span class="n">confs</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>            <span class="c1"># (N,) - which mode model thought was best
</span>    
    <span class="k">return</span> <span class="p">(</span><span class="n">best_mode_by_error</span> <span class="o">==</span> <span class="n">best_mode_by_conf</span><span class="p">).</span><span class="nb">float</span><span class="p">().</span><span class="n">mean</span><span class="p">().</span><span class="n">item</span><span class="p">()</span>
</code></pre></div></div>

<p>With M=6 modes, random confidence assignment would yield ~16.7% accuracy. My model achieves ~48.7%, indicating the confidence head has learned meaningful distinctions between modes, though there’s room for improvement.</p>

<h4 id="brier-score"><strong>Brier Score</strong></h4>

<p>While confidence accuracy is binary (right or wrong), the Brier score measures how well-calibrated the full probability distribution is:</p>

\[\text{Brier} = \frac{1}{N} \sum_{i=1}^{N} \sum_{m=1}^{M} \left(c_i^{(m)} - y_i^{(m)}\right)^2\]

<p>where \(y_i^{(m)} = 1\) if mode \(m\) has the lowest error for sample \(i\), and \(0\) otherwise.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">compute_brier_score</span><span class="p">(</span><span class="n">trajs</span><span class="p">,</span> <span class="n">confs</span><span class="p">,</span> <span class="n">gt</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
    <span class="s">"""
    Brier score for confidence calibration.
    
    Measures the mean squared error between predicted confidence distribution
    and the one-hot "true" distribution (where the best mode gets 1.0).
    
    Lower is better. A perfectly calibrated model placing all confidence
    on the correct mode achieves 0.0. Uniform confidence (1/M each) on
    M=6 modes yields Brier ≈ 0.83.
    """</span>
    <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">trajs</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">gt_exp</span> <span class="o">=</span> <span class="n">gt</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="n">expand_as</span><span class="p">(</span><span class="n">trajs</span><span class="p">)</span>
    <span class="n">mask_exp</span> <span class="o">=</span> <span class="n">mask</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="n">expand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>
    
    <span class="n">diff</span> <span class="o">=</span> <span class="n">trajs</span> <span class="o">-</span> <span class="n">gt_exp</span>
    <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">mask_exp</span>
    <span class="n">ade_per_mode</span> <span class="o">=</span> <span class="n">dist</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">mask_exp</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="n">best_mode</span> <span class="o">=</span> <span class="n">ade_per_mode</span><span class="p">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>             <span class="c1"># (N,)
</span>    
    <span class="c1"># Create one-hot target distribution
</span>    <span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">confs</span><span class="p">)</span>                    <span class="c1"># (N, M)
</span>    <span class="n">target</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">),</span> <span class="n">best_mode</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
    
    <span class="c1"># Brier score: MSE between predicted and target distributions
</span>    <span class="k">return</span> <span class="p">((</span><span class="n">confs</span> <span class="o">-</span> <span class="n">target</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">).</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="n">mean</span><span class="p">().</span><span class="n">item</span><span class="p">()</span>
</code></pre></div></div>

<p>My model achieves a Brier score of ~0.63, better than uniform but indicating the confidence probabilities could be sharper and more decisive.</p>

<h2 id="baseline-models">Baseline Models</h2>

<p>Before developing complex neural architectures, I should establish performance baselines using classical kinematic models and a simple learned approach.</p>

<h3 id="constant-velocity-cv-baseline">Constant Velocity (CV) Baseline</h3>

<p>The simplest physics-based model assumes the agent will continue moving at its current velocity indefinitely. Given the last two valid history positions, we estimate velocity and linearly extrapolate:</p>

\[\mathbf{v} = \frac{\mathbf{p}_{t_2} - \mathbf{p}_{t_1}}{\Delta t \cdot (t_2 - t_1)}\]

\[\hat{\mathbf{p}}_{t+h} = \mathbf{p}_{t_2} + \mathbf{v} \cdot (\Delta t \cdot h), \quad h = 1, \ldots, T_f\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># baseline.py - Constant Velocity Implementation
</span>
<span class="n">DT</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># Time step between frames (seconds)
</span>
<span class="k">def</span> <span class="nf">constant_velocity_baseline</span><span class="p">(</span><span class="n">history_positions</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span>
                               <span class="n">future_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="s">"""
    CV baseline: assume constant velocity equal to the last observed velocity.

    history_positions: (N, H, 2) with NaNs for missing history
    future_len: number of future steps to predict

    Returns:
        preds: (N, future_len, 2)
    """</span>
    <span class="n">N</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">history_positions</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">future_len</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">hist</span> <span class="o">=</span> <span class="n">history_positions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>          <span class="c1"># (H, 2)
</span>        <span class="n">valid</span> <span class="o">=</span> <span class="o">~</span><span class="n">np</span><span class="p">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">hist</span><span class="p">).</span><span class="nb">any</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">valid_idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">valid</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_idx</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">continue</span>  <span class="c1"># No history -&gt; predict zeros
</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_idx</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Only one point -&gt; stay stationary
</span>            <span class="n">last_pos</span> <span class="o">=</span> <span class="n">hist</span><span class="p">[</span><span class="n">valid_idx</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
            <span class="n">preds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">last_pos</span>
            <span class="k">continue</span>

        <span class="c1"># Use last two valid points for velocity estimation
</span>        <span class="n">t1</span><span class="p">,</span> <span class="n">t2</span> <span class="o">=</span> <span class="n">valid_idx</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">valid_idx</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">p1</span><span class="p">,</span> <span class="n">p2</span> <span class="o">=</span> <span class="n">hist</span><span class="p">[</span><span class="n">t1</span><span class="p">],</span> <span class="n">hist</span><span class="p">[</span><span class="n">t2</span><span class="p">]</span>

        <span class="n">v</span> <span class="o">=</span> <span class="p">(</span><span class="n">p2</span> <span class="o">-</span> <span class="n">p1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">DT</span> <span class="o">*</span> <span class="p">(</span><span class="n">t2</span> <span class="o">-</span> <span class="n">t1</span><span class="p">))</span>  <span class="c1"># velocity vector (m/s)
</span>        <span class="n">last_pos</span> <span class="o">=</span> <span class="n">p2</span>

        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">future_len</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">preds</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">last_pos</span> <span class="o">+</span> <span class="n">v</span> <span class="o">*</span> <span class="p">(</span><span class="n">DT</span> <span class="o">*</span> <span class="n">h</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">preds</span>
</code></pre></div></div>

<h3 id="constant-acceleration-ca-baseline">Constant Acceleration (CA) Baseline</h3>

<p>A more sophisticated physics model estimates acceleration from the last three valid points:</p>

\[\mathbf{v}_{01} = \frac{\mathbf{p}_1 - \mathbf{p}_0}{\Delta t \cdot (t_1 - t_0)}, \quad \mathbf{v}_{12} = \frac{\mathbf{p}_2 - \mathbf{p}_1}{\Delta t \cdot (t_2 - t_1)}\]

\[\mathbf{a} = \frac{\mathbf{v}_{12} - \mathbf{v}_{01}}{\Delta t \cdot (t_2 - t_0) / 2}\]

\[\hat{\mathbf{p}}_{t+h} = \mathbf{p}_2 + \mathbf{v}_{12} \cdot t + \frac{1}{2}\mathbf{a} \cdot t^2, \quad t = \Delta t \cdot h\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">constant_acceleration_baseline</span><span class="p">(</span><span class="n">history_positions</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span>
                                   <span class="n">future_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="s">"""
    CA baseline: estimate constant acceleration from the last three valid points.
    Falls back to CV if insufficient points.
    """</span>
    <span class="n">N</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">history_positions</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">future_len</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">hist</span> <span class="o">=</span> <span class="n">history_positions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">valid</span> <span class="o">=</span> <span class="o">~</span><span class="n">np</span><span class="p">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">hist</span><span class="p">).</span><span class="nb">any</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">valid_idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">valid</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_idx</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
            <span class="c1"># Fallback to CV behavior
</span>            <span class="k">continue</span>

        <span class="c1"># Use last 3 valid points to estimate acceleration
</span>        <span class="n">t0</span><span class="p">,</span> <span class="n">t1</span><span class="p">,</span> <span class="n">t2</span> <span class="o">=</span> <span class="n">valid_idx</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">],</span> <span class="n">valid_idx</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">valid_idx</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">p0</span><span class="p">,</span> <span class="n">p1</span><span class="p">,</span> <span class="n">p2</span> <span class="o">=</span> <span class="n">hist</span><span class="p">[</span><span class="n">t0</span><span class="p">],</span> <span class="n">hist</span><span class="p">[</span><span class="n">t1</span><span class="p">],</span> <span class="n">hist</span><span class="p">[</span><span class="n">t2</span><span class="p">]</span>

        <span class="c1"># Velocities between consecutive points
</span>        <span class="n">v01</span> <span class="o">=</span> <span class="p">(</span><span class="n">p1</span> <span class="o">-</span> <span class="n">p0</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">DT</span> <span class="o">*</span> <span class="p">(</span><span class="n">t1</span> <span class="o">-</span> <span class="n">t0</span><span class="p">))</span>
        <span class="n">v12</span> <span class="o">=</span> <span class="p">(</span><span class="n">p2</span> <span class="o">-</span> <span class="n">p1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">DT</span> <span class="o">*</span> <span class="p">(</span><span class="n">t2</span> <span class="o">-</span> <span class="n">t1</span><span class="p">))</span>

        <span class="c1"># Crude acceleration estimate
</span>        <span class="n">a</span> <span class="o">=</span> <span class="p">(</span><span class="n">v12</span> <span class="o">-</span> <span class="n">v01</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">DT</span> <span class="o">*</span> <span class="p">(</span><span class="n">t2</span> <span class="o">-</span> <span class="n">t0</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.0</span><span class="p">)</span>
        <span class="n">v_last</span> <span class="o">=</span> <span class="n">v12</span>
        <span class="n">last_pos</span> <span class="o">=</span> <span class="n">p2</span>

        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">future_len</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">DT</span> <span class="o">*</span> <span class="n">h</span>
            <span class="n">preds</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">last_pos</span> <span class="o">+</span> <span class="n">v_last</span> <span class="o">*</span> <span class="n">t</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">a</span> <span class="o">*</span> <span class="p">(</span><span class="n">t</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">preds</span>
</code></pre></div></div>

<h3 id="mlp-baseline">MLP Baseline</h3>

<p>The first learned baseline uses a simple Multi-Layer Perceptron that maps flattened history positions to future trajectory coordinates:</p>

\[\hat{\mathbf{Y}} = \text{MLP}(\text{flatten}(\mathbf{H}))\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TrajMLP</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    Simple MLP baseline:
      input: flattened history positions (H * 2)
      output: flattened future positions (T * 2)
    """</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">history_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">future_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">256</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="n">in_dim</span> <span class="o">=</span> <span class="n">history_len</span> <span class="o">*</span> <span class="mi">2</span>
        <span class="n">out_dim</span> <span class="o">=</span> <span class="n">future_len</span> <span class="o">*</span> <span class="mi">2</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="s">"""
        x: (N, H, 2) history positions
        Returns: (N, T, 2) future predictions
        """</span>
        <span class="n">N</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
        <span class="n">x_flat</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">H</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">out_flat</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">net</span><span class="p">(</span><span class="n">x_flat</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">out_flat</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</code></pre></div></div>

<p><img src="/CS163-Projects-2025Fall/assets/images/team36/baseline_compare.png" alt="Baseline Comparison Placeholder" />
<em>Fig 3. Comparison of baseline predictions. CV produces straight-line extrapolations, CA adds curvature, and MLP learns smoother patterns but still produces unimodal outputs.</em></p>

<hr />

<h2 id="resnet-single-trajectory-model">ResNet Single-Trajectory Model</h2>

<h3 id="motivation">Motivation</h3>

<p>The baseline models ignore crucial scene context; road geometry, lane markings, and traffic rules that constrain where vehicles can feasibly travel. The ResNet model addresses this by consuming rasterized bird’s-eye-view maps alongside agent history.</p>

<h3 id="architecture-design">Architecture Design</h3>

<p>I adapt ResNet-50 for trajectory regression by:</p>

<ol>
  <li><strong>Modifying Input Channels:</strong> replacing the first convolutional layer to accept rasters with additional history channels</li>
  <li><strong>Replacing Classification Head:</strong> swapping the 1000=class softmax head with a linear layer predicting \(T_f \times 2\) coordinates</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># train_resnet.py - ResNet Architecture
</span>
<span class="k">class</span> <span class="nc">LyftResNetModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>

        <span class="n">history_num_frames</span> <span class="o">=</span> <span class="n">cfg</span><span class="p">[</span><span class="s">"model_params"</span><span class="p">][</span><span class="s">"history_num_frames"</span><span class="p">]</span>  <span class="c1"># 10
</span>        <span class="n">future_num_frames</span> <span class="o">=</span> <span class="n">cfg</span><span class="p">[</span><span class="s">"model_params"</span><span class="p">][</span><span class="s">"future_num_frames"</span><span class="p">]</span>    <span class="c1"># 50
</span>
        <span class="c1"># Input channels: 3 (RGB satellite) + (history_frames + 1) * 2 (agent positions)
</span>        <span class="n">num_history_channels</span> <span class="o">=</span> <span class="p">(</span><span class="n">history_num_frames</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span>
        <span class="n">num_in_channels</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">+</span> <span class="n">num_history_channels</span>  <span class="c1"># 3 + 22 = 25
</span>
        <span class="c1"># Load pretrained ResNet-50
</span>        <span class="n">backbone</span> <span class="o">=</span> <span class="n">resnet50</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="c1"># Replace first conv to accept custom input channels
</span>        <span class="n">backbone</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span>
            <span class="n">num_in_channels</span><span class="p">,</span>
            <span class="n">backbone</span><span class="p">.</span><span class="n">conv1</span><span class="p">.</span><span class="n">out_channels</span><span class="p">,</span>
            <span class="n">kernel_size</span><span class="o">=</span><span class="n">backbone</span><span class="p">.</span><span class="n">conv1</span><span class="p">.</span><span class="n">kernel_size</span><span class="p">,</span>
            <span class="n">stride</span><span class="o">=</span><span class="n">backbone</span><span class="p">.</span><span class="n">conv1</span><span class="p">.</span><span class="n">stride</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="n">backbone</span><span class="p">.</span><span class="n">conv1</span><span class="p">.</span><span class="n">padding</span><span class="p">,</span>
            <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Replace classification head with trajectory regression
</span>        <span class="n">num_targets</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">future_num_frames</span>  <span class="c1"># 100 outputs
</span>        <span class="n">in_features</span> <span class="o">=</span> <span class="n">backbone</span><span class="p">.</span><span class="n">fc</span><span class="p">.</span><span class="n">in_features</span>
        <span class="n">backbone</span><span class="p">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">num_targets</span><span class="p">)</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">backbone</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">future_len</span> <span class="o">=</span> <span class="n">future_num_frames</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># (B, T*2)
</span>        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">future_len</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># (B, T, 2)
</span>        <span class="k">return</span> <span class="n">out</span>
</code></pre></div></div>

<h3 id="loss-function-with-temporal-weighting">Loss Function with Temporal Weighting</h3>

<p>I use weighted MSE loss that emphasizes later timesteps, which are more critical for planning:</p>

\[\mathcal{L}_{\text{ResNet}} = \frac{\sum_{t=1}^{T_f} w_t \cdot a_t \cdot \|\hat{\mathbf{y}}_t - \mathbf{y}_t\|^2}{\sum_{t=1}^{T_f} w_t \cdot a_t}\]

<p>where \(w_t\) linearly increases from 0.5 to 2.0 across timesteps, and \(a_t\) is the availability mask.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train_one_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">total_loss</span><span class="p">,</span> <span class="n">total_count</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
        <span class="n">imgs</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s">"image"</span><span class="p">].</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">).</span><span class="nb">float</span><span class="p">()</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s">"target_positions"</span><span class="p">].</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">).</span><span class="nb">float</span><span class="p">()</span>      <span class="c1"># (B, T, 2)
</span>        <span class="n">avail</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s">"target_availabilities"</span><span class="p">].</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">).</span><span class="nb">float</span><span class="p">()</span>  <span class="c1"># (B, T)
</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>

        <span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">target</span><span class="p">.</span><span class="n">shape</span>
        <span class="c1"># Temporal weights: emphasize later timesteps
</span>        <span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="n">T</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

        <span class="n">diff2</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred</span> <span class="o">-</span> <span class="n">target</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>                    <span class="c1"># (B, T, 2)
</span>        <span class="n">mse_per_step</span> <span class="o">=</span> <span class="n">diff2</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>                <span class="c1"># (B, T)
</span>        <span class="n">mse_per_step</span> <span class="o">=</span> <span class="n">mse_per_step</span> <span class="o">*</span> <span class="n">avail</span> <span class="o">*</span> <span class="n">weights</span>   <span class="c1"># Apply masks and weights
</span>        <span class="n">denom</span> <span class="o">=</span> <span class="p">(</span><span class="n">avail</span> <span class="o">*</span> <span class="n">weights</span><span class="p">).</span><span class="nb">sum</span><span class="p">().</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">mse_per_step</span><span class="p">.</span><span class="nb">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">denom</span>

        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">imgs</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">total_count</span> <span class="o">+=</span> <span class="n">imgs</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="n">total_count</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="training-configuration">Training Configuration</h3>

<p>To ensure stable optimization and fast convergence on the 350k-sample Lyft dataset, I will select hyperparameters commonly used for large-scale raster-based trajectory models. A batch size of 64 balances GPU memory usage with gradient stability. Adam with a learning rate of 1e-3 provides rapid early training, while StepLR with γ=0.5 every 3 epochs prevents plateaus and improves late-stage refinement. Ten epochs is sufficient because ResNet-50 is pretrained, and the model only needs to learn the raster-to-trajectory mapping. The raster size is fixed at 224×224 to match the ResNet receptive field and maintain compatibility with the modified backbone.</p>

<table style="width: 100%; border-collapse: collapse; font-size: 16px;">
  <thead>
    <tr>
      <th style="text-align: left; padding: 8px; border-bottom: 2px solid #ccc;">Hyperparameter</th>
      <th style="text-align: left; padding: 8px; border-bottom: 2px solid #ccc;">Value</th>
    </tr>
  </thead>
  <tbody>
    <tr><td style="padding: 8px; border-bottom: 1px solid #eee;">Batch Size</td><td style="padding: 8px; border-bottom: 1px solid #eee;">64</td></tr>
    <tr><td style="padding: 8px; border-bottom: 1px solid #eee;">Learning Rate</td><td style="padding: 8px; border-bottom: 1px solid #eee;">1e-3</td></tr>
    <tr><td style="padding: 8px; border-bottom: 1px solid #eee;">Optimizer</td><td style="padding: 8px; border-bottom: 1px solid #eee;">Adam</td></tr>
    <tr><td style="padding: 8px; border-bottom: 1px solid #eee;">LR Schedule</td><td style="padding: 8px; border-bottom: 1px solid #eee;">StepLR (γ=0.5 every 3 epochs)</td></tr>
    <tr><td style="padding: 8px; border-bottom: 1px solid #eee;">Training Samples</td><td style="padding: 8px; border-bottom: 1px solid #eee;">350,000</td></tr>
    <tr><td style="padding: 8px; border-bottom: 1px solid #eee;">Validation Samples</td><td style="padding: 8px; border-bottom: 1px solid #eee;">35,000</td></tr>
    <tr><td style="padding: 8px; border-bottom: 1px solid #eee;">Epochs</td><td style="padding: 8px; border-bottom: 1px solid #eee;">10</td></tr>
    <tr><td style="padding: 8px;">Input Size</td><td style="padding: 8px;">224 × 224</td></tr>
  </tbody>
</table>

<p><img src="/CS163-Projects-2025Fall/assets/images/team36/resnet_curves.png" alt="ResNet Curves Placeholder" />
<em>Fig 4. ResNet training curves showing loss convergence and validation metric improvements over 10 epochs.</em></p>

<hr />

<h2 id="multimodal-raster--agent-history-model">Multimodal Raster + Agent History Model</h2>

<div style="flex: 1 1 45%; min-width: 300px; text-align: center;">
    <img src="/CS163-Projects-2025Fall/assets/images/team36/scene_2286_multimodal.gif" alt="Scene 2286 Multimodal Prediction" style="width: 100%; border: 1px solid #ccc; border-radius: 5px;" />
    <p><em>Scene 2286 from L5Kit: Comparison on a turn.</em></p>
</div>

<h3 id="visualization-compatibility-wrapper">Visualization Compatibility Wrapper</h3>

<p>Some visualization code expects a simpler interface: feed in position history, get out trajectories. The <code class="language-plaintext highlighter-rouge">WayformerModel</code> wrapper provides this interface while internally using the full raster-based model. When no raster is available (e.g., for quick testing), it creates a dummy zero image and relies solely on agent history:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">WayformerModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    Wrapper class for visualization compatibility.
    
    Provides a simplified (history, mask) -&gt; (trajectories, confidences) interface.
    When called without raster context, it creates a dummy zero image internally,
    so predictions rely entirely on agent motion history.
    
    This is useful for:
    - Quick testing without setting up the full data pipeline
    - Visualization code that doesn't have access to raster images
    - Comparing history-only vs. history+raster performance
    
    Note: Predictions will be less accurate without raster context, as the
    model can't see road geometry, lane markings, or other scene features.
    """</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">25</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span> <span class="o">=</span> <span class="n">cfg</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">RasterTrajectoryModel</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">mask</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="s">"""
        Simplified forward pass using only position history.
        
        Args:
            x: (B, H, 2) history positions in agent-local coordinates
            mask: (B, H) boolean mask (True = valid observation)
        
        Returns:
            trajectories: (B, M, T, 2) predicted future positions
            confidences: (B, M) probability distribution over modes
        """</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">device</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span>
        <span class="n">mp</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">[</span><span class="s">"model_params"</span><span class="p">]</span>

        <span class="n">H_conf</span> <span class="o">=</span> <span class="n">mp</span><span class="p">[</span><span class="s">"history_num_frames"</span><span class="p">]</span>
        <span class="n">T</span> <span class="o">=</span> <span class="n">mp</span><span class="p">[</span><span class="s">"future_num_frames"</span><span class="p">]</span>

        <span class="c1"># Convert positions to [x, y, vx, vy] format
</span>        <span class="n">x_np</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">detach</span><span class="p">().</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">hist_pos</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">x_np</span><span class="p">,</span> <span class="n">nan</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
        
        <span class="c1"># Compute velocities from position differences
</span>        <span class="k">if</span> <span class="n">H</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">vel</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">hist_pos</span><span class="p">)</span>
            <span class="n">vel</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">(</span><span class="n">hist_pos</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span> <span class="o">-</span> <span class="n">hist_pos</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:])</span> <span class="o">/</span> <span class="n">mp</span><span class="p">[</span><span class="s">"step_time"</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">vel</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">hist_pos</span><span class="p">)</span>

        <span class="n">agent_hist</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">hist_pos</span><span class="p">,</span> <span class="n">vel</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (B, H, 4)
</span>
        <span class="c1"># Pad or truncate to expected history length
</span>        <span class="k">if</span> <span class="n">H</span> <span class="o">&lt;</span> <span class="n">H_conf</span><span class="p">:</span>
            <span class="n">pad</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">B</span><span class="p">,</span> <span class="n">H_conf</span> <span class="o">-</span> <span class="n">H</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="n">agent_hist</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">pad</span><span class="p">,</span> <span class="n">agent_hist</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">agent_hist</span> <span class="o">=</span> <span class="n">agent_hist</span><span class="p">[:,</span> <span class="o">-</span><span class="n">H_conf</span><span class="p">:,</span> <span class="p">:]</span>

        <span class="n">agent_hist</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">agent_hist</span><span class="p">).</span><span class="nb">float</span><span class="p">().</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">hist_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">H_conf</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Create dummy zero image (no raster context)
</span>        <span class="c1"># The model will rely entirely on agent history for predictions
</span>        <span class="n">C</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">cnn</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">weight</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Get expected channels from model
</span>        <span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

        <span class="n">batch</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">"image"</span><span class="p">:</span> <span class="n">img</span><span class="p">,</span>
            <span class="s">"agent_hist"</span><span class="p">:</span> <span class="n">agent_hist</span><span class="p">,</span>
            <span class="s">"agent_hist_mask"</span><span class="p">:</span> <span class="n">hist_mask</span><span class="p">,</span>
            <span class="s">"target"</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
            <span class="s">"avail"</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
        <span class="p">}</span>

        <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">pred</span><span class="p">[</span><span class="s">"trajectories"</span><span class="p">],</span> <span class="n">pred</span><span class="p">[</span><span class="s">"confidences"</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">load_from_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">):</span>
        <span class="s">"""Load model weights from a training checkpoint."""</span>
        <span class="n">ckpt</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">ckpt</span><span class="p">[</span><span class="s">"model_state_dict"</span><span class="p">])</span>
        <span class="k">return</span> <span class="bp">self</span>
</code></pre></div></div>

<p>This wrapper is intentionally limited. Without raster context, the model is essentially blind to road geometry. It’s meant for quick experiments and visualization, not production inference. For best results, always use the full <code class="language-plaintext highlighter-rouge">RasterTrajectoryModel</code> with proper raster images.</p>

<h3 id="the-need-for-multimodality">The Need for Multimodality</h3>

<p>A fundamental limitation of the ResNet model is that it produces a single deterministic trajectory. Real driving scenarios are inherently uncertain. At an intersection, a vehicle might turn left, right, or go straight with roughly equal probability. A single prediction cannot capture this uncertainty and may produce an “averaged” trajectory that lies between the true modes, satisfying none of them.</p>

<p>Our final model addresses this by predicting <strong>M = 6 diverse trajectory hypotheses</strong> with associated confidence scores, enabling downstream planners to reason about multiple possible futures.</p>

<h2 id="model-and-design-rationale">Model and Design Rationale</h2>

<p>To build an effective trajectory-prediction model, I evaluated several architectural options used in recent motion-forecasting literature. The final design reflects a balance of prediction accuracy, computational efficiency, and compatibility with rasterized map inputs.</p>

<p>The core idea is that future motion depends on two complementary factors:</p>

<ol>
  <li><strong>Scene context</strong> like road geometry, lane direction, obstacles, sidewalks, intersections</li>
  <li><strong>Agent dynamics</strong> such as recent motion patterns such as speed, heading changes, and acceleration</li>
</ol>

<p>No single modality captures both. The architecture therefore merges visual map features and temporal agent features in a lightweight but expressive way.</p>

<h4 id="cnn-backbone-spatial-encoding"><strong>CNN Backbone (Spatial Encoding).</strong></h4>
<p>Rasterized semantic maps behave like images, and convolutional networks extract spatial patterns efficiently. Alternatives such as Vision Transformers or graph networks were considered, but they introduce significantly higher computational cost and require much larger datasets to train effectively. A compact 4-layer CNN offers a good trade-off: fast training, stable gradients, and strong performance on structured map inputs.</p>

<h4 id="agent-history-mlp-motion-encoding"><strong>Agent-History MLP (Motion Encoding).</strong></h4>
<p>The history vector is only <code class="language-plaintext highlighter-rouge">[x, y, vx, vy] × 10</code> frames. This is low-dimensional and does not need a heavy recurrent model. I chose a 2-layer MLP because it captures short-term trends (slowing, turning, drifting) at minimal cost. More complex sequence models (GRUs, temporal transformers) were tested but added overhead with little improvement for this representation.</p>

<h4 id="feature-fusion-context--dynamics"><strong>Feature Fusion (Context × Dynamics).</strong></h4>
<p>The model must interpret agent motion <em>within</em> the context of the environment. Fusing the CNN embedding with the history embedding lets the network learn combined features such as deceleration toward an intersection, or drifting toward a lane boundary.</p>

<h4 id="multi-modal-prediction-head-m--6"><strong>Multi-Modal Prediction Head (M = 6).</strong></h4>
<p>Future motion is uncertain, especially at intersections. A single deterministic trajectory collapses multiple possible futures into an unrealistic average. Multi-modal heads were chosen over mixture-density networks or CVAE-based sampling because they:</p>
<ul>
  <li>produce consistent, interpretable modes</li>
  <li>train stably</li>
  <li>are easy for downstream planners to consume</li>
</ul>

<p>Six modes (M = 6) gave the best balance between coverage of diverse futures and computational cost.</p>

<p>Together, these design choices yield a model that is fast to train, easy to interpret, and capable of predicting diverse, realistic futures in complex urban environments.</p>

<h3 id="architecture-overview">Architecture Overview</h3>

<p>The architecture consists of four main components:</p>

<ol>
  <li><strong>CNN Backbone:</strong> Processes semantic raster maps to extract spatial features</li>
  <li><strong>History Encoder MLP:</strong> Encodes agent motion history (position + velocity)</li>
  <li><strong>Fusion Module:</strong> Combines visual and motion features</li>
  <li><strong>Prediction Heads:</strong> Output multiple trajectories and confidence distribution</li>
</ol>

<p><img src="/CS163-Projects-2025Fall/assets/images/team36/model_architecture.png" alt="Multimodal Architecture Placeholder" />
<em>Fig 5. Multimodal model architecture. The CNN backbone processes rasterized scene context while the History MLP encodes agent dynamics. Fused features are decoded into M=6 trajectory hypotheses with confidence scores.</em></p>

<h3 id="detailed-architecture-implementation">Detailed Architecture Implementation</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">RasterTrajectoryModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    CNN (semantic raster) + MLP (agent history) -&gt; multi-modal trajectory.
    
    Architecture:
    - CNN backbone: 4-layer ConvNet with BatchNorm, outputs 256-dim feature
    - History MLP: 2-layer MLP encoding [x, y, vx, vy] × 10 frames
    - Fusion: 2-layer MLP combining CNN + history features
    - Trajectory Head: Linear layer outputting M × T × 2 coordinates
    - Confidence Head: Linear layer outputting M logits → softmax
    """</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="n">mp</span> <span class="o">=</span> <span class="n">cfg</span><span class="p">[</span><span class="s">"model_params"</span><span class="p">]</span>
        <span class="n">arch</span> <span class="o">=</span> <span class="n">cfg</span><span class="p">[</span><span class="s">"model_arch"</span><span class="p">]</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">history_len</span> <span class="o">=</span> <span class="n">mp</span><span class="p">[</span><span class="s">"history_num_frames"</span><span class="p">]</span>  <span class="c1"># 10
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">future_len</span> <span class="o">=</span> <span class="n">mp</span><span class="p">[</span><span class="s">"future_num_frames"</span><span class="p">]</span>    <span class="c1"># 50
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">n_modes</span> <span class="o">=</span> <span class="n">arch</span><span class="p">[</span><span class="s">"n_modes"</span><span class="p">]</span>               <span class="c1"># 6
</span>        <span class="n">d_model</span> <span class="o">=</span> <span class="n">arch</span><span class="p">[</span><span class="s">"d_model"</span><span class="p">]</span>                    <span class="c1"># 256
</span>        <span class="n">dropout</span> <span class="o">=</span> <span class="n">arch</span><span class="p">[</span><span class="s">"dropout"</span><span class="p">]</span>                    <span class="c1"># 0.1
</span>
        <span class="c1"># ============ CNN BACKBONE ============
</span>        <span class="c1"># Lightweight 4-layer ConvNet for fast training
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">cnn</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="c1"># Layer 1: 224 -&gt; 112
</span>            <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>

            <span class="c1"># Layer 2: 112 -&gt; 56
</span>            <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>

            <span class="c1"># Layer 3: 56 -&gt; 28
</span>            <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">128</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>

            <span class="c1"># Layer 4: 28 -&gt; 14 -&gt; 1 (global pool)
</span>            <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>

            <span class="n">nn</span><span class="p">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>  <span class="c1"># Global average pooling
</span>        <span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">cnn_out_dim</span> <span class="o">=</span> <span class="mi">256</span>

        <span class="c1"># ============ HISTORY ENCODER ============
</span>        <span class="c1"># MLP over flattened [x, y, vx, vy] × history_len
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">hist_mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">history_len</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">d_model</span><span class="p">),</span>  <span class="c1"># 40 -&gt; 256
</span>            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">),</span>               <span class="c1"># 256 -&gt; 256
</span>            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># ============ FUSION MODULE ============
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">fusion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">cnn_out_dim</span> <span class="o">+</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">),</span>  <span class="c1"># 512 -&gt; 256
</span>            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">),</span>
            <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">),</span>                     <span class="c1"># 256 -&gt; 256
</span>            <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># ============ PREDICTION HEADS ============
</span>        <span class="c1"># Trajectory head: outputs M modes × T timesteps × 2 coordinates
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">out_traj</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">n_modes</span> <span class="o">*</span> <span class="bp">self</span><span class="p">.</span><span class="n">future_len</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># Confidence head: outputs M mode logits
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">out_conf</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">n_modes</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s">"image"</span><span class="p">]</span>        <span class="c1"># (B, C, H, W)
</span>        <span class="n">hist</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s">"agent_hist"</span><span class="p">]</span>  <span class="c1"># (B, H, 4) where 4 = [x, y, vx, vy]
</span>
        <span class="n">B</span> <span class="o">=</span> <span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Extract CNN features from raster
</span>        <span class="n">feat_img</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">cnn</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>           <span class="c1"># (B, 256, 1, 1)
</span>        <span class="n">feat_img</span> <span class="o">=</span> <span class="n">feat_img</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>    <span class="c1"># (B, 256)
</span>
        <span class="c1"># Extract history features
</span>        <span class="n">feat_hist</span> <span class="o">=</span> <span class="n">hist</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>       <span class="c1"># (B, H*4) = (B, 40)
</span>        <span class="n">feat_hist</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">hist_mlp</span><span class="p">(</span><span class="n">feat_hist</span><span class="p">)</span>  <span class="c1"># (B, 256)
</span>
        <span class="c1"># Fuse visual and motion features
</span>        <span class="n">fused</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">fusion</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">feat_img</span><span class="p">,</span> <span class="n">feat_hist</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># (B, 256)
</span>
        <span class="c1"># Generate outputs
</span>        <span class="n">traj_flat</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">out_traj</span><span class="p">(</span><span class="n">fused</span><span class="p">)</span>       <span class="c1"># (B, M*T*2)
</span>        <span class="n">confid_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">out_conf</span><span class="p">(</span><span class="n">fused</span><span class="p">)</span>   <span class="c1"># (B, M)
</span>
        <span class="c1"># Reshape trajectory output
</span>        <span class="n">traj</span> <span class="o">=</span> <span class="n">traj_flat</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">n_modes</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">future_len</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># (B, M, T, 2)
</span>        <span class="c1"># Convert confidence logits to probability distribution
</span>        <span class="n">confid</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">confid_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>                   <span class="c1"># (B, M)
</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s">"trajectories"</span><span class="p">:</span> <span class="n">traj</span><span class="p">,</span>
            <span class="s">"confidences"</span><span class="p">:</span> <span class="n">confid</span><span class="p">,</span>           <span class="c1"># probs (for eval)
</span>            <span class="s">"confid_logits"</span><span class="p">:</span> <span class="n">confid_logits</span><span class="p">,</span>  <span class="c1"># logits (for loss)
</span>        <span class="p">}</span>
</code></pre></div></div>

<h2 id="data-pipeline">Data Pipeline</h2>

<p>We need a system that converts the raw <strong>Lyft L5Kit</strong> samples into the exact tensors the model can train on. In this project, the dataset does not directly provide the features the model needs, so the pipeline builds them step-by-step.</p>

<p>It begins with the <strong>rasterized map image</strong> from <strong>L5Kit</strong> and <strong>normalizes</strong> it so the <strong>CNN</strong> can process it. It then takes the agent’s <strong>past positions</strong> and computes <strong>velocities</strong> from frame-to-frame differences, forming the <strong>motion-history vector</strong> <code class="language-plaintext highlighter-rouge">[x, y, vx, vy]</code> for each timestep. Because different agents have different amounts of valid history, the pipeline <strong>pads or trims</strong> the sequence so every sample has a <strong>fixed history length</strong>, ensuring consistent input size during batching.</p>

<p>Finally, it extracts the <strong>future positions</strong> from the dataset. These become the model’s <strong>regression targets</strong>.</p>

<p>By the time a batch reaches the network, each item has been transformed into a uniform structure:</p>

<ul>
  <li>a <strong>normalized raster</strong> for the <strong>CNN</strong></li>
  <li>a <strong>fixed-length motion-history tensor</strong> for the <strong>MLP</strong></li>
  <li><strong>future trajectories</strong> for the loss function</li>
</ul>

<p>This preprocessing step is what allows the model to treat every sample identically, <strong>train efficiently</strong>, and learn both <strong>scene context</strong> and <strong>agent dynamics</strong> from the raw dataset.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">RasterLyftDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="s">"""
    Wraps L5Kit AgentDataset, returning:
      - image: semantic raster (C, H, W)
      - agent_hist: (H, 4) containing [x, y, vx, vy] per timestep
      - agent_hist_mask: (H,) boolean mask for padding
      - target: (T, 2) future positions
      - avail: (T,) availability mask
    """</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">agent_dataset</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

        <span class="c1"># 1) Normalize raster image
</span>        <span class="n">img</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">"image"</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.0</span>  <span class="c1"># (C, H, W)
</span>
        <span class="c1"># 2) Compute velocity from position differences
</span>        <span class="n">hist_pos</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">"history_positions"</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">hist_pos</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">hist_pos</span><span class="p">,</span> <span class="n">nan</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="n">H0</span> <span class="o">=</span> <span class="n">hist_pos</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">H0</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">vel</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">hist_pos</span><span class="p">)</span>
            <span class="n">vel</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">=</span> <span class="p">(</span><span class="n">hist_pos</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">hist_pos</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="bp">self</span><span class="p">.</span><span class="n">mp</span><span class="p">[</span><span class="s">"step_time"</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">vel</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">hist_pos</span><span class="p">)</span>

        <span class="c1"># Concatenate position and velocity: [x, y, vx, vy]
</span>        <span class="n">agent_hist</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">hist_pos</span><span class="p">,</span> <span class="n">vel</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (H0, 4)
</span>
        <span class="c1"># Pad or truncate to fixed history length
</span>        <span class="k">if</span> <span class="n">H0</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="p">.</span><span class="n">history_len</span><span class="p">:</span>
            <span class="n">pad</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="p">.</span><span class="n">history_len</span> <span class="o">-</span> <span class="n">H0</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="n">agent_hist</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">pad</span><span class="p">,</span> <span class="n">agent_hist</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">agent_hist</span> <span class="o">=</span> <span class="n">agent_hist</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="p">.</span><span class="n">history_len</span><span class="p">:]</span>

        <span class="c1"># 3) Prepare target and availability
</span>        <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">"target_positions"</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">avail</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">"target_availabilities"</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s">"image"</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">img</span><span class="p">),</span>
            <span class="s">"agent_hist"</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">agent_hist</span><span class="p">),</span>
            <span class="s">"target"</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">target</span><span class="p">),</span>
            <span class="s">"avail"</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">avail</span><span class="p">),</span>
        <span class="p">}</span>
</code></pre></div></div>

<hr />

<h2 id="loss-function-derivation">Loss Function Derivation</h2>

<h3 id="the-challenge-of-multimodal-learning">The Challenge of Multimodal Learning</h3>

<p>Training multimodal predictors presents a fundamental challenge: which of the M predicted modes should match the single ground truth trajectory? A naive approach of averaging loss across all modes would cause all predictions to collapse to the mean. We need a loss function that:</p>

<ol>
  <li>Encourages at least one mode to match the ground truth well</li>
  <li>Encourages diversity among modes</li>
  <li>Trains the confidence head to predict which mode is best</li>
</ol>

<h3 id="soft-winner-takes-all-loss">Soft Winner-Takes-All Loss</h3>

<p>We implement a <strong>soft winner-takes-all (WTA)</strong> loss that allows gradients to flow primarily to the mode closest to the ground truth while maintaining diversity:</p>

<h4 id="step-1-compute-per-mode-errors"><strong>Step 1: Compute per-mode errors</strong></h4>

<p>For each mode \(m\), compute the total L2 error:</p>

\[E_m = \sum_{t=1}^{T_f} a_t \cdot \|\hat{\mathbf{y}}_t^{(m)} - \mathbf{y}_t\|_2\]

<p>where \(a_t\) is the availability mask.</p>

<h4 id="step-2-soft-mode-selection"><strong>Step 2: Soft mode selection</strong></h4>

<p>Instead of hard selection (which prevents gradient flow to non-winning modes), we use temperature-scaled softmax:</p>

\[w_m = \frac{\exp(-E_m / \tau)}{\sum_{m'} \exp(-E_{m'} / \tau)}\]

<p>where \(\tau = 0.1\) is a temperature parameter. Lower \(\tau\) makes the weighting sharper.</p>

<h4 id="step-3-regression-loss"><strong>Step 3: Regression loss</strong></h4>

<p>The weighted regression loss becomes:</p>

\[\mathcal{L}_{\text{reg}} = \sum_{m=1}^{M} w_m \cdot E_m\]

<h4 id="step-4-confidence-loss"><strong>Step 4: Confidence loss</strong></h4>

<p>We train the confidence head to predict which mode is best using cross-entropy:</p>

\[m^* = \arg\min_m E_m\]

\[\mathcal{L}_{\text{conf}} = -\log(c_{m^*})\]

<h4 id="step-5-total-loss"><strong>Step 5: Total loss</strong></h4>

\[\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{reg}} + \lambda_{\text{conf}} \cdot \mathcal{L}_{\text{conf}}\]

<p>where \(\lambda_{\text{conf}} = 0.5\).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">MultiModalTrajectoryLoss</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    Multi-modal L2 loss with soft winner-takes-all + confidence cross-entropy.
    """</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="n">Dict</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">n_modes</span> <span class="o">=</span> <span class="n">cfg</span><span class="p">[</span><span class="s">"model_arch"</span><span class="p">][</span><span class="s">"n_modes"</span><span class="p">]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">tau</span> <span class="o">=</span> <span class="mf">0.1</span>          <span class="c1"># Temperature for soft WTA
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">lambda_conf</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c1"># Weight for confidence loss
</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">pred</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="n">traj</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="s">"trajectories"</span><span class="p">]</span>   <span class="c1"># (B, M, T, 2)
</span>        <span class="n">confid</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="s">"confidences"</span><span class="p">]</span>  <span class="c1"># (B, M)
</span>
        <span class="n">gt</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s">"target"</span><span class="p">]</span>          <span class="c1"># (B, T, 2)
</span>        <span class="n">avail</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s">"avail"</span><span class="p">]</span>        <span class="c1"># (B, T)
</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">traj</span><span class="p">.</span><span class="n">shape</span>

        <span class="c1"># Expand ground truth to match trajectory shape
</span>        <span class="n">gt_exp</span> <span class="o">=</span> <span class="n">gt</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="n">expand_as</span><span class="p">(</span><span class="n">traj</span><span class="p">)</span>         <span class="c1"># (B, M, T, 2)
</span>        <span class="n">avail_exp</span> <span class="o">=</span> <span class="n">avail</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="n">expand</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>   <span class="c1"># (B, M, T)
</span>
        <span class="c1"># Compute L2 distances per mode per timestep
</span>        <span class="n">diff</span> <span class="o">=</span> <span class="n">traj</span> <span class="o">-</span> <span class="n">gt_exp</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">diff</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">avail_exp</span>      <span class="c1"># (B, M, T)
</span>
        <span class="c1"># Sum over timesteps to get per-mode error
</span>        <span class="n">mode_errors</span> <span class="o">=</span> <span class="n">dist</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (B, M)
</span>
        <span class="c1"># Find best mode (for confidence supervision)
</span>        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">best_mode</span> <span class="o">=</span> <span class="n">mode_errors</span><span class="p">.</span><span class="nb">min</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (B,)
</span>
        <span class="c1"># Soft WTA weights (temperature-scaled softmax)
</span>        <span class="n">w</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="o">-</span><span class="n">mode_errors</span> <span class="o">/</span> <span class="bp">self</span><span class="p">.</span><span class="n">tau</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (B, M)
</span>        <span class="n">reg_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="n">mode_errors</span><span class="p">).</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span>

        <span class="c1"># Cross-entropy loss for confidence head
</span>        <span class="n">confid_logits</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="s">"confid_logits"</span><span class="p">]</span>  <span class="c1"># (B, M)
</span>        <span class="n">conf_loss</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">confid_logits</span><span class="p">,</span> <span class="n">best_mode</span><span class="p">)</span>

        <span class="c1"># ===== Compute ADE/FDE for logging =====
</span>        <span class="n">best_traj</span> <span class="o">=</span> <span class="n">traj</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">traj</span><span class="p">.</span><span class="n">device</span><span class="p">),</span> <span class="n">best_mode</span><span class="p">]</span>  <span class="c1"># (B, T, 2)
</span>        <span class="n">valid_counts</span> <span class="o">=</span> <span class="n">avail</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">last_idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">avail</span><span class="p">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">valid_counts</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)).</span><span class="nb">float</span><span class="p">().</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">fde</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span>
            <span class="n">best_traj</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">B</span><span class="p">),</span> <span class="n">last_idx</span><span class="p">]</span> <span class="o">-</span> <span class="n">gt</span><span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">B</span><span class="p">),</span> <span class="n">last_idx</span><span class="p">],</span>
            <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
        <span class="p">).</span><span class="n">mean</span><span class="p">()</span>

        <span class="c1"># ADE over best mode only
</span>        <span class="n">best_dist</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">best_traj</span> <span class="o">-</span> <span class="n">gt</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">avail</span>  <span class="c1"># (B, T)
</span>        <span class="n">ade</span> <span class="o">=</span> <span class="n">best_dist</span><span class="p">.</span><span class="nb">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">avail</span><span class="p">.</span><span class="nb">sum</span><span class="p">().</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">total</span> <span class="o">=</span> <span class="n">reg_loss</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">lambda_conf</span> <span class="o">*</span> <span class="n">conf_loss</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s">"total"</span><span class="p">:</span> <span class="n">total</span><span class="p">,</span>
            <span class="s">"reg"</span><span class="p">:</span> <span class="n">reg_loss</span><span class="p">,</span>
            <span class="s">"conf"</span><span class="p">:</span> <span class="n">conf_loss</span><span class="p">,</span>
            <span class="s">"ade"</span><span class="p">:</span> <span class="n">ade</span><span class="p">,</span>
            <span class="s">"fde"</span><span class="p">:</span> <span class="n">fde</span><span class="p">,</span>
        <span class="p">}</span>
</code></pre></div></div>

<hr />

<h2 id="training-procedure">Training Procedure</h2>

<p>The configuration is designed around the spatial and temporal characteristics of urban driving while keeping training efficient. A history length of <code class="language-plaintext highlighter-rouge">10 frames</code> at <code class="language-plaintext highlighter-rouge">10 Hz</code> captures <code class="language-plaintext highlighter-rouge">1 second</code> of recent motion, which is enough to infer short-term intent such as braking, accelerating, or initiating a turn. Predicting <code class="language-plaintext highlighter-rouge">50 future frames</code> covers a <code class="language-plaintext highlighter-rouge">5-second horizon</code>, which is the standard window used in motion-forecasting benchmarks. A <code class="language-plaintext highlighter-rouge">224×224 raster</code> at <code class="language-plaintext highlighter-rouge">0.5 m/pixel</code> yields a <code class="language-plaintext highlighter-rouge">~112 m</code> field of view, which is large enough to include intersections, road geometry, and nearby agents. The ego-center offset shifts the raster forward so the model sees more of the road ahead, where the agent’s future motion depends most.</p>

<p>A batch size of <code class="language-plaintext highlighter-rouge">128</code> provides stable gradients without exceeding GPU memory. Only a few epochs are needed because the dataset is extremely large and each epoch covers hundreds of thousands of samples. A learning rate of <code class="language-plaintext highlighter-rouge">1e-3</code> with weight decay of <code class="language-plaintext highlighter-rouge">1e-4</code> is a well-behaved optimization setup for <code class="language-plaintext highlighter-rouge">Adam</code> on mid-sized networks. The architectural choices of <code class="language-plaintext highlighter-rouge">256-dim embeddings</code>, <code class="language-plaintext highlighter-rouge">6 trajectory modes</code>, and <code class="language-plaintext highlighter-rouge">0.1 dropout</code> strike a balance between capacity, regularization, and training speed, enabling the model to learn diverse, realistic futures without overfitting.</p>

<h3 id="training-configuration-1">Training Configuration</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">build_cfg</span><span class="p">():</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s">"format_version"</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
        <span class="s">"model_params"</span><span class="p">:</span> <span class="p">{</span>
            <span class="s">"history_num_frames"</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>    <span class="c1"># 1 second of history
</span>            <span class="s">"future_num_frames"</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>     <span class="c1"># 5 seconds of future
</span>            <span class="s">"step_time"</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>            <span class="c1"># 10 Hz
</span>            <span class="s">"render_ego_history"</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
            <span class="s">"render_ego_center"</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s">"raster_params"</span><span class="p">:</span> <span class="p">{</span>
            <span class="s">"raster_size"</span><span class="p">:</span> <span class="p">[</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">],</span>
            <span class="s">"pixel_size"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>    <span class="c1"># meters per pixel
</span>            <span class="s">"ego_center"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>   <span class="c1"># ego position in raster
</span>            <span class="s">"map_type"</span><span class="p">:</span> <span class="s">"py_semantic"</span><span class="p">,</span>   <span class="c1"># semantic map (road semantics)
</span>        <span class="p">},</span>
        <span class="s">"train_data_loader"</span><span class="p">:</span> <span class="p">{</span>
            <span class="s">"batch_size"</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
            <span class="s">"shuffle"</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
            <span class="s">"num_workers"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s">"training"</span><span class="p">:</span> <span class="p">{</span>
            <span class="s">"num_epochs"</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
            <span class="s">"learning_rate"</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">,</span>
            <span class="s">"weight_decay"</span><span class="p">:</span> <span class="mf">1e-4</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="s">"model_arch"</span><span class="p">:</span> <span class="p">{</span>
            <span class="s">"d_model"</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span>
            <span class="s">"n_modes"</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>
            <span class="s">"dropout"</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">}</span>
</code></pre></div></div>

<h3 id="training-loop-with-mixed-precision">Training Loop with Mixed Precision</h3>

<p>We can employ several optimization techniques for efficient training:</p>

<ol>
  <li><strong>Mixed Precision Training:</strong> Using <code class="language-plaintext highlighter-rouge">float16</code> for forward/backward passes to reduce memory and accelerate computation.</li>
  <li><strong>Gradient Clipping:</strong> Preventing exploding gradients (<code class="language-plaintext highlighter-rouge">max norm = 5.0</code>).</li>
  <li><strong>AdamW Optimizer:</strong> Uses <code class="language-plaintext highlighter-rouge">weight decay</code> regularization for better generalization.</li>
  <li><strong>Cosine Annealing LR:</strong> Smooth learning rate decay over <code class="language-plaintext highlighter-rouge">num_epochs</code>.</li>
  <li><strong>Best Checkpoint Saving:</strong> Based on minimizing <code class="language-plaintext highlighter-rouge">validation ADE</code>.</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">resume_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">"cpu"</span><span class="p">)</span>
    <span class="n">cfg</span> <span class="o">=</span> <span class="n">build_cfg</span><span class="p">()</span>
    <span class="n">tp</span> <span class="o">=</span> <span class="n">cfg</span><span class="p">[</span><span class="s">"training"</span><span class="p">]</span>

    <span class="c1"># Initialize model, loss, optimizer
</span>    <span class="n">model</span> <span class="o">=</span> <span class="n">RasterTrajectoryModel</span><span class="p">(</span><span class="n">cfg</span><span class="p">,</span> <span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Model parameters: </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="p">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">())</span><span class="si">:</span><span class="p">,</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

    <span class="n">criterion</span> <span class="o">=</span> <span class="n">MultiModalTrajectoryLoss</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="n">AdamW</span><span class="p">(</span>
        <span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span>
        <span class="n">lr</span><span class="o">=</span><span class="n">tp</span><span class="p">[</span><span class="s">"learning_rate"</span><span class="p">],</span>
        <span class="n">weight_decay</span><span class="o">=</span><span class="n">tp</span><span class="p">[</span><span class="s">"weight_decay"</span><span class="p">],</span>
    <span class="p">)</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">optim</span><span class="p">.</span><span class="n">lr_scheduler</span><span class="p">.</span><span class="n">CosineAnnealingLR</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="p">,</span> <span class="n">T_max</span><span class="o">=</span><span class="n">tp</span><span class="p">[</span><span class="s">"num_epochs"</span><span class="p">],</span> <span class="n">eta_min</span><span class="o">=</span><span class="mf">1e-5</span>
    <span class="p">)</span>
    <span class="n">scaler</span> <span class="o">=</span> <span class="n">GradScaler</span><span class="p">()</span>  <span class="c1"># For mixed precision
</span>
    <span class="n">best_val_ade</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s">"inf"</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="c1"># ========== TRAINING ==========
</span>        <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">train_losses</span> <span class="o">=</span> <span class="p">{</span><span class="s">"total"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s">"reg"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s">"conf"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s">"ade"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s">"fde"</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>

        <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s">"Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">num_epochs</span><span class="si">}</span><span class="s"> [Train]"</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">.</span><span class="n">items</span><span class="p">()}</span>

            <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="c1"># Mixed precision forward pass
</span>            <span class="k">with</span> <span class="n">autocast</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float16</span><span class="p">):</span>
                <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
                <span class="n">losses</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
                <span class="n">loss_total</span> <span class="o">=</span> <span class="n">losses</span><span class="p">[</span><span class="s">"total"</span><span class="p">]</span>

            <span class="c1"># Scaled backward pass
</span>            <span class="n">scaler</span><span class="p">.</span><span class="n">scale</span><span class="p">(</span><span class="n">loss_total</span><span class="p">).</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">scaler</span><span class="p">.</span><span class="n">unscale_</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
            <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="mf">5.0</span><span class="p">)</span>  <span class="c1"># Gradient clipping
</span>            <span class="n">scaler</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
            <span class="n">scaler</span><span class="p">.</span><span class="n">update</span><span class="p">()</span>

            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">train_losses</span><span class="p">:</span>
                <span class="n">train_losses</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">+=</span> <span class="n">losses</span><span class="p">[</span><span class="n">k</span><span class="p">].</span><span class="n">item</span><span class="p">()</span>

            <span class="n">pbar</span><span class="p">.</span><span class="n">set_postfix</span><span class="p">({</span>
                <span class="s">"loss"</span><span class="p">:</span> <span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">losses</span><span class="p">[</span><span class="s">'total'</span><span class="p">].</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">,</span>
                <span class="s">"ade"</span><span class="p">:</span> <span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">losses</span><span class="p">[</span><span class="s">'ade'</span><span class="p">].</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">,</span>
                <span class="s">"fde"</span><span class="p">:</span> <span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">losses</span><span class="p">[</span><span class="s">'fde'</span><span class="p">].</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">,</span>
            <span class="p">})</span>

        <span class="c1"># ========== VALIDATION ==========
</span>        <span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
        <span class="n">val_losses</span> <span class="o">=</span> <span class="p">{</span><span class="s">"total"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s">"reg"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s">"conf"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s">"ade"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s">"fde"</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>

        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">.</span><span class="n">items</span><span class="p">()}</span>
                <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
                <span class="n">losses</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>

                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">val_losses</span><span class="p">:</span>
                    <span class="n">val_losses</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">+=</span> <span class="n">losses</span><span class="p">[</span><span class="n">k</span><span class="p">].</span><span class="n">item</span><span class="p">()</span>

        <span class="n">scheduler</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

        <span class="c1"># Save best checkpoint
</span>        <span class="k">if</span> <span class="n">val_losses</span><span class="p">[</span><span class="s">"ade"</span><span class="p">]</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">best_val_ade</span><span class="p">:</span>
            <span class="n">best_val_ade</span> <span class="o">=</span> <span class="n">val_losses</span><span class="p">[</span><span class="s">"ade"</span><span class="p">]</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_loader</span><span class="p">)</span>
            <span class="n">torch</span><span class="p">.</span><span class="n">save</span><span class="p">({</span>
                <span class="s">"epoch"</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
                <span class="s">"model_state_dict"</span><span class="p">:</span> <span class="n">model</span><span class="p">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="s">"optimizer_state_dict"</span><span class="p">:</span> <span class="n">optimizer</span><span class="p">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="s">"val_ade"</span><span class="p">:</span> <span class="n">best_val_ade</span><span class="p">,</span>
                <span class="s">"cfg"</span><span class="p">:</span> <span class="n">cfg</span><span class="p">,</span>
            <span class="p">},</span> <span class="s">"best_raster_model.pth"</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">model</span>
</code></pre></div></div>

<h3 id="training-metrics-summary">Training Metrics Summary</h3>

<p><img src="/CS163-Projects-2025Fall/assets/images/team36/multimodal_training_curves.png" alt="Multimodal Curves Placeholder" />
<em>Fig 6. Training and validation curves for the multimodal model showing loss convergence, ADE/FDE improvements, and learning rate schedule.</em></p>

<hr />

<h2 id="quantitative-results">Quantitative Results</h2>

<h3 id="final-model-comparison">Final Model Comparison</h3>

<div style="width: 100%; display: flex; justify-content: center;">
<table style="width: 95%; border-collapse: collapse; border: 1px solid #ddd; margin: 20px 0;">
  <thead>
    <tr style="border-bottom: 2px solid #333; background-color: #f6f8fa;">
      <th style="padding: 12px; text-align: left;">Model</th>
      <th style="padding: 12px; text-align: left;">Modalities</th>
      <th style="padding: 12px; text-align: left;">ADE ↓</th>
      <th style="padding: 12px; text-align: left;">FDE ↓</th>
      <th style="padding: 12px; text-align: left;">MR@2m ↓</th>
    </tr>
  </thead>
  <tbody>
    <tr style="border-bottom: 1px solid #eee;">
      <td style="padding: 10px;">Constant Velocity</td>
      <td style="padding: 10px;"><code>1</code></td>
      <td style="padding: 10px;"><code>8.42</code></td>
      <td style="padding: 10px;"><code>15.67</code></td>
      <td style="padding: 10px;"><code>89.0%</code></td>
    </tr>
    <tr style="border-bottom: 1px solid #eee;">
      <td style="padding: 10px;">Constant Acceleration</td>
      <td style="padding: 10px;"><code>1</code></td>
      <td style="padding: 10px;"><code>7.81</code></td>
      <td style="padding: 10px;"><code>14.23</code></td>
      <td style="padding: 10px;"><code>85.0%</code></td>
    </tr>
    <tr style="border-bottom: 1px solid #eee;">
      <td style="padding: 10px;">MLP Baseline</td>
      <td style="padding: 10px;"><code>1</code></td>
      <td style="padding: 10px;"><code>5.34</code></td>
      <td style="padding: 10px;"><code>9.87</code></td>
      <td style="padding: 10px;"><code>72.0%</code></td>
    </tr>
    <tr style="border-bottom: 1px solid #eee;">
      <td style="padding: 10px;">ResNet Single-Traj</td>
      <td style="padding: 10px;"><code>1</code></td>
      <td style="padding: 10px;"><code>3.12</code></td>
      <td style="padding: 10px;"><code>5.89</code></td>
      <td style="padding: 10px;"><code>48.0%</code></td>
    </tr>
    <tr style="border-bottom: 1px solid #eee;">
      <td style="padding: 10px;">Multimodal (by confidence)</td>
      <td style="padding: 10px;"><code>6</code></td>
      <td style="padding: 10px;"><code>1.10</code></td>
      <td style="padding: 10px;"><code>2.40</code></td>
      <td style="padding: 10px;"><code>27.2%</code></td>
    </tr>
    <tr>
      <td style="padding: 10px;">Multimodal (oracle best)</td>
      <td style="padding: 10px;"><code>6</code></td>
      <td style="padding: 10px;"><code>0.45</code></td>
      <td style="padding: 10px;"><code>0.95</code></td>
      <td style="padding: 10px;"><code>13.4%</code></td>
    </tr>
  </tbody>
</table>
</div>

<h3 id="multimodal-model-detailed-metrics">Multimodal Model Detailed Metrics</h3>

<div style="width: 100%; display: flex; justify-content: center;">
<table style="width: 95%; border-collapse: collapse; border: 1px solid #ddd; margin: 20px 0;">
  <thead>
    <tr style="border-bottom: 2px solid #333; background-color: #f6f8fa;">
      <th style="padding: 12px; text-align: left;">Metric</th>
      <th style="padding: 12px; text-align: left;">Value</th>
      <th style="padding: 12px; text-align: left;">Interpretation</th>
    </tr>
  </thead>
  <tbody>
    <tr style="border-bottom: 1px solid #eee;">
      <td style="padding: 10px;">ADE (by confidence)</td>
      <td style="padding: 10px;"><code>1.10 m</code></td>
      <td style="padding: 10px;">Error using model's highest-confidence mode</td>
    </tr>
    <tr style="border-bottom: 1px solid #eee;">
      <td style="padding: 10px;">FDE (by confidence)</td>
      <td style="padding: 10px;"><code>2.40 m</code></td>
      <td style="padding: 10px;">Final position error using model's choice</td>
    </tr>
    <tr style="border-bottom: 1px solid #eee;">
      <td style="padding: 10px;">minADE (oracle)</td>
      <td style="padding: 10px;"><code>0.45 m</code></td>
      <td style="padding: 10px;">Best possible with perfect mode selection</td>
    </tr>
    <tr style="border-bottom: 1px solid #eee;">
      <td style="padding: 10px;">minFDE (oracle)</td>
      <td style="padding: 10px;"><code>0.95 m</code></td>
      <td style="padding: 10px;">Best possible final error across all modes</td>
    </tr>
    <tr style="border-bottom: 1px solid #eee;">
      <td style="padding: 10px;">Confidence Accuracy</td>
      <td style="padding: 10px;"><code>48.7%</code></td>
      <td style="padding: 10px;">How often the model picks the best mode</td>
    </tr>
    <tr>
      <td style="padding: 10px;">Brier Score</td>
      <td style="padding: 10px;"><code>0.626</code></td>
      <td style="padding: 10px;">Confidence calibration quality (lower = better)</td>
    </tr>
  </tbody>
</table>
</div>

<h3 id="trajectory-behavior-analysis">Trajectory Behavior Analysis</h3>

<p>Not all trajectories are equally difficult to predict. A vehicle traveling straight on a highway is far more predictable than one navigating a complex intersection. To understand where my model excels and struggles, I classify trajectories by their cumulative curvature and analyze performance separately.</p>

<h4 id="curvature-based-classification">Curvature-Based Classification</h4>

<p>I compute the total angular change along each ground-truth trajectory. Trajectories with cumulative curvature below a threshold (0.3 radians ≈ 17°) are classified as “straight,” while those above are “turning”:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">compute_turn_metrics</span><span class="p">(</span><span class="n">trajs</span><span class="p">,</span> <span class="n">confs</span><span class="p">,</span> <span class="n">gt</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">turn_threshold</span><span class="o">=</span><span class="mf">0.3</span><span class="p">):</span>
    <span class="s">"""
    Classifies trajectories as straight vs turning based on cumulative
    angular change, then computes metrics separately for each category.
    
    The curvature is computed by summing the absolute angle between
    consecutive velocity vectors along the ground-truth path.
    
    Args:
        trajs: (N, M, T, 2) predicted trajectories
        confs: (N, M) confidence scores
        gt: (N, T, 2) ground truth
        mask: (N, T) validity mask
        turn_threshold: radians of cumulative curvature to classify as turn
    
    Returns:
        dict with counts and per-category metrics
    """</span>
    <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">trajs</span><span class="p">.</span><span class="n">shape</span>
    <span class="n">gt_np</span> <span class="o">=</span> <span class="n">gt</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">mask_np</span> <span class="o">=</span> <span class="n">mask</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span>
    
    <span class="n">curvatures</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">total_angle</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">valid_t</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">mask_np</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nb">sum</span><span class="p">())</span>
        
        <span class="k">if</span> <span class="n">valid_t</span> <span class="o">&gt;=</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">valid_t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
                <span class="c1"># Velocity vectors between consecutive points
</span>                <span class="n">v1</span> <span class="o">=</span> <span class="n">gt_np</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span> <span class="o">-</span> <span class="n">gt_np</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">v2</span> <span class="o">=</span> <span class="n">gt_np</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">gt_np</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">]</span>
                
                <span class="c1"># Signed angle between vectors using cross and dot products
</span>                <span class="n">cross</span> <span class="o">=</span> <span class="n">v1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">v2</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">v1</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">v2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">dot</span> <span class="o">=</span> <span class="n">v1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">v2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">v1</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">v2</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">total_angle</span> <span class="o">+=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arctan2</span><span class="p">(</span><span class="n">cross</span><span class="p">,</span> <span class="n">dot</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="p">))</span>
        
        <span class="n">curvatures</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">total_angle</span><span class="p">)</span>
    
    <span class="n">curvatures</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">curvatures</span><span class="p">)</span>
    <span class="n">is_turn</span> <span class="o">=</span> <span class="n">curvatures</span> <span class="o">&gt;</span> <span class="n">turn_threshold</span>
    
    <span class="n">n_straight</span> <span class="o">=</span> <span class="p">(</span><span class="o">~</span><span class="n">is_turn</span><span class="p">).</span><span class="nb">sum</span><span class="p">()</span>
    <span class="n">n_turn</span> <span class="o">=</span> <span class="n">is_turn</span><span class="p">.</span><span class="nb">sum</span><span class="p">()</span>
    
    <span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">"n_straight"</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_straight</span><span class="p">),</span>
        <span class="s">"n_turn"</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_turn</span><span class="p">)</span>
    <span class="p">}</span>
    
    <span class="c1"># Compute metrics for straight trajectories
</span>    <span class="k">if</span> <span class="n">n_straight</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">straight_idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">is_turn</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">results</span><span class="p">[</span><span class="s">"straight_minADE"</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_min_ade</span><span class="p">(</span>
            <span class="n">trajs</span><span class="p">[</span><span class="n">straight_idx</span><span class="p">],</span> <span class="n">gt</span><span class="p">[</span><span class="n">straight_idx</span><span class="p">],</span> <span class="n">mask</span><span class="p">[</span><span class="n">straight_idx</span><span class="p">])</span>
        <span class="n">results</span><span class="p">[</span><span class="s">"straight_conf_acc"</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_conf_accuracy</span><span class="p">(</span>
            <span class="n">trajs</span><span class="p">[</span><span class="n">straight_idx</span><span class="p">],</span> <span class="n">confs</span><span class="p">[</span><span class="n">straight_idx</span><span class="p">],</span> 
            <span class="n">gt</span><span class="p">[</span><span class="n">straight_idx</span><span class="p">],</span> <span class="n">mask</span><span class="p">[</span><span class="n">straight_idx</span><span class="p">])</span>
    
    <span class="c1"># Compute metrics for turning trajectories
</span>    <span class="k">if</span> <span class="n">n_turn</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">turn_idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">is_turn</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">results</span><span class="p">[</span><span class="s">"turn_minADE"</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_min_ade</span><span class="p">(</span>
            <span class="n">trajs</span><span class="p">[</span><span class="n">turn_idx</span><span class="p">],</span> <span class="n">gt</span><span class="p">[</span><span class="n">turn_idx</span><span class="p">],</span> <span class="n">mask</span><span class="p">[</span><span class="n">turn_idx</span><span class="p">])</span>
        <span class="n">results</span><span class="p">[</span><span class="s">"turn_conf_acc"</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_conf_accuracy</span><span class="p">(</span>
            <span class="n">trajs</span><span class="p">[</span><span class="n">turn_idx</span><span class="p">],</span> <span class="n">confs</span><span class="p">[</span><span class="n">turn_idx</span><span class="p">],</span> 
            <span class="n">gt</span><span class="p">[</span><span class="n">turn_idx</span><span class="p">],</span> <span class="n">mask</span><span class="p">[</span><span class="n">turn_idx</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="n">results</span>
</code></pre></div></div>

<h4 id="why-this-matters">Why This Matters</h4>

<p>The breakdown reveals an interesting asymmetry in model behavior. Straight trajectories are predicted with exceptional accuracy (minADE ~0.17m) because they have low inherent uncertainty. There’s really only one plausible future. However, confidence accuracy on straight trajectories is notably poor (~21.8%), suggesting the model hedges its bets even when it shouldn’t.</p>

<p>Turning trajectories, which make up the vast majority of the validation set (~95%), show higher minADE (~0.46m) reflecting their greater complexity, but substantially better confidence accuracy (~50%). This indicates the model has learned to distinguish between different turning behaviors (sharp left vs. gentle curve vs. lane change) and assigns confidence accordingly.</p>

<p>This analysis suggests a potential improvement: the model could benefit from learning to recognize when a scenario is “simple” (straight road, no intersection) and concentrate confidence on a single mode, rather than always hedging across multiple hypotheses.</p>

<h3 id="analysis">Analysis</h3>

<p>The progression from physics-based baselines to our multimodal architecture demonstrates the cumulative value of each design decision. The Constant Velocity baseline achieves <code class="language-plaintext highlighter-rouge">8.42m ADE</code> by simply extrapolating the last observed velocity, failing catastrophically when agents accelerate, brake, or turn. Adding acceleration modeling in the CA baseline provides modest improvement to <code class="language-plaintext highlighter-rouge">7.81m ADE</code>, but still cannot capture the complex dynamics of real driving behavior.</p>

<p>The transition to learned approaches marks a significant turning point. Our MLP baseline, despite having no scene context, reduces ADE to <code class="language-plaintext highlighter-rouge">5.34m</code> by learning statistical patterns from the training distribution. The ResNet model then demonstrates the critical importance of visual scene understanding, it achieves <code class="language-plaintext highlighter-rouge">3.12m ADE</code>, a <code class="language-plaintext highlighter-rouge">41% improvement</code> over the MLP. This confirms that road geometry, lane markings, and intersection structure provide essential constraints on feasible future trajectories.</p>

<p>Our multimodal architecture achieves the best performance across all metrics, with <code class="language-plaintext highlighter-rouge">1.10m ADE</code> using the model’s confidence-selected mode. More revealing is the oracle analysis: when we select the best of the six predicted modes for each sample, ADE drops to just <code class="language-plaintext highlighter-rouge">0.45m</code> and miss rate falls to <code class="language-plaintext highlighter-rouge">13.4%</code>. This <code class="language-plaintext highlighter-rouge">59% gap</code> between confidence-selected and oracle performance indicates that the model generates good trajectory hypotheses but has significant room for improvement in confidence calibration.</p>

<h3 id="trajectory-type-breakdown">Trajectory Type Breakdown</h3>

<div style="width: 100%; display: flex; justify-content: center;">
<table style="width: 95%; border-collapse: collapse; border: 1px solid #ddd; margin: 20px 0;">
  <thead>
    <tr style="border-bottom: 2px solid #333; background-color: #f6f8fa;">
      <th style="padding: 12px; text-align: left;">Category</th>
      <th style="padding: 12px; text-align: left;">Samples</th>
      <th style="padding: 12px; text-align: left;">minADE</th>
      <th style="padding: 12px; text-align: left;">Confidence Accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr style="border-bottom: 1px solid #eee;">
      <td style="padding: 10px;">Straight</td>
      <td style="padding: 10px;"><code>998</code> (<code>4.6%</code>)</td>
      <td style="padding: 10px;"><code>0.17 m</code></td>
      <td style="padding: 10px;"><code>21.8%</code></td>
    </tr>
    <tr>
      <td style="padding: 10px;">Turning</td>
      <td style="padding: 10px;"><code>20,627</code> (<code>95.4%</code>)</td>
      <td style="padding: 10px;"><code>0.46 m</code></td>
      <td style="padding: 10px;"><code>50.0%</code></td>
    </tr>
  </tbody>
</table>
</div>

<p>The turn versus straight breakdown reveals interesting patterns in model behavior. Straight trajectories are predicted with exceptional accuracy, which is expected given their lower inherent uncertainty. However, confidence accuracy on straight trajectories is notably poor at <code>21.8%</code>, suggesting the model struggles to identify when a trajectory will be straight versus when it might curve.</p>

<p>Turning trajectories, which comprise <code>95.4%</code> of our evaluation set, show higher minADE (<code>0.46m</code>) reflecting their greater complexity, but substantially better confidence accuracy at <code>50.0%</code>. This indicates the model has learned meaningful distinctions between different turning behaviors.</p>

<h3 id="oracle-performance-gap">Oracle Performance Gap</h3>

<p>The gap between confidence-selected metrics and oracle metrics represents the potential improvement achievable through better confidence calibration alone:</p>

<div style="width: 100%; display: flex; justify-content: center;">
<table style="width: 95%; border-collapse: collapse; border: 1px solid #ddd; margin: 20px 0;">
  <thead>
    <tr style="border-bottom: 2px solid #333; background-color: #f6f8fa;">
      <th style="padding: 12px; text-align: left;">Metric</th>
      <th style="padding: 12px; text-align: left;">By Confidence</th>
      <th style="padding: 12px; text-align: left;">Oracle</th>
      <th style="padding: 12px; text-align: left;">Potential Improvement</th>
    </tr>
  </thead>
  <tbody>
    <tr style="border-bottom: 1px solid #eee;">
      <td style="padding: 10px;">ADE</td>
      <td style="padding: 10px;"><code>1.10 m</code></td>
      <td style="padding: 10px;"><code>0.45 m</code></td>
      <td style="padding: 10px;"><code>59%</code> reduction possible</td>
    </tr>
    <tr style="border-bottom: 1px solid #eee;">
      <td style="padding: 10px;">FDE</td>
      <td style="padding: 10px;"><code>2.40 m</code></td>
      <td style="padding: 10px;"><code>0.95 m</code></td>
      <td style="padding: 10px;"><code>60%</code> reduction possible</td>
    </tr>
    <tr>
      <td style="padding: 10px;">MR@2m</td>
      <td style="padding: 10px;"><code>27.2%</code></td>
      <td style="padding: 10px;"><code>13.4%</code></td>
      <td style="padding: 10px;"><code>51%</code> reduction possible</td>
    </tr>
  </tbody>
</table>
</div>

<h2 id="inference-utilities">Inference Utilities</h2>

<p>Before visualizing predictions, I need utilities that convert raw dataset samples into the format expected by each model. These functions bridge the gap between L5Kit’s data format and my model’s input requirements.</p>

<h3 id="building-raster-batches-for-inference">Building Raster Batches for Inference</h3>

<p>The multimodal model expects a specific input dictionary with normalized images, velocity-augmented history, and properly shaped tensors. This function handles all the preprocessing:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">build_raster_batch_from_sample</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="s">"""
    Converts a single L5Kit sample into the batch format expected by
    RasterTrajectoryModel.
    
    This replicates the preprocessing done by RasterLyftDataset but for
    a single sample during inference/visualization.
    
    Args:
        data: dict from AgentDataset or EgoDataset containing:
            - "image": (C, H, W) uint8 raster image
            - "history_positions": (H0, 2) past positions, may have NaN
            - "history_availabilities": (H0,) optional validity mask
        cfg: model configuration dict
        device: torch device for output tensors
    
    Returns:
        batch: dict with keys matching model's forward() signature
    """</span>
    <span class="n">mp</span> <span class="o">=</span> <span class="n">cfg</span><span class="p">[</span><span class="s">"model_params"</span><span class="p">]</span>
    <span class="n">history_len</span> <span class="o">=</span> <span class="n">mp</span><span class="p">[</span><span class="s">"history_num_frames"</span><span class="p">]</span>
    <span class="n">step_time</span> <span class="o">=</span> <span class="n">mp</span><span class="p">[</span><span class="s">"step_time"</span><span class="p">]</span>
    <span class="n">future_len</span> <span class="o">=</span> <span class="n">mp</span><span class="p">[</span><span class="s">"future_num_frames"</span><span class="p">]</span>

    <span class="c1"># 1) Normalize image: [0, 255] -&gt; [0, 1]
</span>    <span class="n">img</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">"image"</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.0</span>      <span class="c1"># (C, H, W)
</span>    <span class="n">img_t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">img</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># (1, C, H, W)
</span>
    <span class="c1"># 2) Process history positions and compute velocities
</span>    <span class="n">hist_pos</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">"history_positions"</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># (H0, 2)
</span>    <span class="n">hist_pos</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">hist_pos</span><span class="p">,</span> <span class="n">nan</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
    <span class="n">H0</span> <span class="o">=</span> <span class="n">hist_pos</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Velocity = position difference / time step
</span>    <span class="k">if</span> <span class="n">H0</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">vel</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">hist_pos</span><span class="p">)</span>
        <span class="n">vel</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">=</span> <span class="p">(</span><span class="n">hist_pos</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">hist_pos</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="n">step_time</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">vel</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">hist_pos</span><span class="p">)</span>

    <span class="c1"># Concatenate position and velocity: [x, y, vx, vy]
</span>    <span class="n">agent_hist</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">hist_pos</span><span class="p">,</span> <span class="n">vel</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (H0, 4)
</span>
    <span class="c1"># 3) Pad or truncate to fixed history length
</span>    <span class="k">if</span> <span class="n">H0</span> <span class="o">&lt;</span> <span class="n">history_len</span><span class="p">:</span>
        <span class="c1"># Pad at the beginning (older timesteps)
</span>        <span class="n">pad</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">history_len</span> <span class="o">-</span> <span class="n">H0</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">agent_hist</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">pad</span><span class="p">,</span> <span class="n">agent_hist</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Keep most recent frames
</span>        <span class="n">agent_hist</span> <span class="o">=</span> <span class="n">agent_hist</span><span class="p">[</span><span class="o">-</span><span class="n">history_len</span><span class="p">:]</span>

    <span class="n">agent_hist_t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">agent_hist</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># 4) Build history availability mask
</span>    <span class="c1"># True = invalid/padded, False = valid observation
</span>    <span class="n">hist_avail</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"history_availabilities"</span><span class="p">,</span>
                          <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">H0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)).</span><span class="n">astype</span><span class="p">(</span><span class="nb">bool</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">H0</span> <span class="o">&lt;</span> <span class="n">history_len</span><span class="p">:</span>
        <span class="n">pad_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">history_len</span> <span class="o">-</span> <span class="n">H0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
        <span class="n">hist_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span><span class="o">~</span><span class="n">pad_mask</span><span class="p">,</span> <span class="o">~</span><span class="n">hist_avail</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">hist_mask</span> <span class="o">=</span> <span class="o">~</span><span class="n">hist_avail</span><span class="p">[</span><span class="o">-</span><span class="n">history_len</span><span class="p">:]</span>

    <span class="n">hist_mask_t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">hist_mask</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># 5) Dummy target tensors (not used during inference, but required by forward())
</span>    <span class="n">target_t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">future_len</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">avail_t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">future_len</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s">"image"</span><span class="p">:</span> <span class="n">img_t</span><span class="p">,</span>
        <span class="s">"agent_hist"</span><span class="p">:</span> <span class="n">agent_hist_t</span><span class="p">,</span>
        <span class="s">"agent_hist_mask"</span><span class="p">:</span> <span class="n">hist_mask_t</span><span class="p">,</span>
        <span class="s">"target"</span><span class="p">:</span> <span class="n">target_t</span><span class="p">,</span>
        <span class="s">"avail"</span><span class="p">:</span> <span class="n">avail_t</span><span class="p">,</span>
    <span class="p">}</span>
</code></pre></div></div>

<h3 id="extracting-all-mode-predictions">Extracting All Mode Predictions</h3>

<p>For visualization, I often want to see all trajectory hypotheses, not just the most confident one. This function returns the full mode distribution:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">predict_all_modes</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">model_multi</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="s">"""
    Runs inference and returns all M trajectory modes with their probabilities.
    
    Useful for visualization where we want to show the full distribution
    of possible futures, with line opacity proportional to confidence.
    
    Args:
        data: raw sample from L5Kit dataset
        model_multi: trained RasterTrajectoryModel
        cfg: model configuration
        device: torch device
    
    Returns:
        trajs: (M, T, 2) numpy array of trajectory coordinates
        probs: (M,) numpy array of probabilities summing to 1.0
    """</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="n">build_raster_batch_from_sample</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">model_multi</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">trajs</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="s">"trajectories"</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>    <span class="c1"># (M, T, 2)
</span>        <span class="n">confs</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="s">"confidences"</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>     <span class="c1"># (M,) - already softmaxed
</span>        
        <span class="n">probs</span> <span class="o">=</span> <span class="n">confs</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">trajs</span> <span class="o">=</span> <span class="n">trajs</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span>
        
    <span class="k">return</span> <span class="n">trajs</span><span class="p">,</span> <span class="n">probs</span>


<span class="k">def</span> <span class="nf">predict_best_mode</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">model_multi</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="s">"""
    Returns only the highest-confidence trajectory prediction.
    
    Simpler interface when you just need the model's "best guess"
    without the full mode distribution.
    """</span>
    <span class="n">trajs</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="n">predict_all_modes</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">model_multi</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    <span class="n">best_idx</span> <span class="o">=</span> <span class="n">probs</span><span class="p">.</span><span class="n">argmax</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">trajs</span><span class="p">[</span><span class="n">best_idx</span><span class="p">]</span>  <span class="c1"># (T, 2)
</span></code></pre></div></div>

<h3 id="trajectory-distance-trimming">Trajectory Distance Trimming</h3>

<p>For cleaner visualizations, especially in animations, I trim trajectories to a maximum travel distance rather than showing the full 5-second prediction:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">trim_to_distance</span><span class="p">(</span><span class="n">traj</span><span class="p">,</span> <span class="n">max_dist_m</span><span class="p">):</span>
    <span class="s">"""
    Trims a trajectory so it doesn't extend beyond max_dist_m from the start.
    
    Useful for visualization: a 5-second prediction at highway speeds can
    extend 150+ meters, which may go off-screen. Trimming to 30m keeps
    the visualization focused on the near-term prediction.
    
    Args:
        traj: (T, 2) trajectory coordinates
        max_dist_m: maximum cumulative distance in meters
    
    Returns:
        trimmed trajectory, shape (K, 2) where K &lt;= T
    """</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">traj</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">traj</span>
    
    <span class="c1"># Compute cumulative distance traveled
</span>    <span class="n">displacements</span> <span class="o">=</span> <span class="n">traj</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">traj</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>                    <span class="c1"># (T-1, 2)
</span>    <span class="n">step_distances</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">norm</span><span class="p">(</span><span class="n">displacements</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (T-1,)
</span>    <span class="n">cumulative_dist</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">step_distances</span><span class="p">)</span>             <span class="c1"># (T-1,)
</span>    
    <span class="c1"># Find where we exceed the threshold
</span>    <span class="n">within_range</span> <span class="o">=</span> <span class="n">cumulative_dist</span> <span class="o">&lt;=</span> <span class="n">max_dist_m</span>
    
    <span class="k">if</span> <span class="n">within_range</span><span class="p">.</span><span class="nb">any</span><span class="p">():</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">within_range</span><span class="p">.</span><span class="nb">sum</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># +1 to include the starting point
</span>    <span class="k">else</span><span class="p">:</span>
        <span class="n">k</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># Keep at least the first point
</span>    
    <span class="k">return</span> <span class="n">traj</span><span class="p">[:</span><span class="n">k</span><span class="p">]</span>
</code></pre></div></div>

<h2 id="qualitative-visualizations">Qualitative Visualizations</h2>

<h3 id="resnet-vs-multimodal-comparison">ResNet vs Multimodal Comparison</h3>

<p><img src="/CS163-Projects-2025Fall/assets/images/team36/compare_baseline_vs_multi.png" alt="Compare Placeholder" />
<em>Fig 7. Left: ResNet produces a single trajectory that may “average” between modes. Right: Multimodal model produces diverse hypotheses capturing left turn, right turn, and straight possibilities.</em></p>

<h3 id="high-uncertainty-intersection-example">High-Uncertainty Intersection Example</h3>

<p><img src="/CS163-Projects-2025Fall/assets/images/team36/high_uncertainty_case_example.png" alt="Uncertainty Placeholder" />
<em>Fig 8. At intersections, the model should predict multiple plausible futures (turn left, go straight, turn right) with appropriate confidence distribution.</em></p>

<h3 id="high-uncertainty-intersection-from-model">High-Uncertainty Intersection from Model</h3>

<p><img src="/CS163-Projects-2025Fall/assets/images/team36/high_uncertainty_case.png" alt="Uncertainty Placeholder" />
<em>Fig 9. At intersections, this is what my model predicts with confidence distribution.</em></p>

<h3 id="animated-trajectory">Animated Trajectory</h3>

<p>This GIF shows the comparison between the ResNet and Multi-modal models. I removed all of the other 5 trajectory lines for the multi-modal model to showcase the trajectory prediction with the highest accuracy. You can also see that in the ResNet model, it’s having trouble to predict the curve since really this model focuses on going straight.</p>

<p><img src="/CS163-Projects-2025Fall/assets/images/team36/scene.gif" alt="GIF Placeholder" />
<em>Fig 10. Animated visualization showing predicted trajectories unfolding alongside a curved road.</em></p>

<hr />

<h2 id="discussion">Discussion</h2>

<h3 id="lessons-learned">Lessons learned</h3>

<p>Bringing the raster into the model changed everything. Once the network could actually “see” lane geometry, intersections, and road constraints, the predictions immediately tightened up. Instead of guessing a curve based only on past positions, the model started following the shape of the road.</p>

<p>Adding explicit velocity features ended up being more important than I expected. Giving the model 
\((v_x, v_y)\) directly kept it from overshooting turns or lagging behind when an agent was accelerating. It essentially grounded the model in the agent’s motion state instead of making it infer everything from scratch.</p>

<p>Multimodality solved a huge chunk of the ambiguity problem. At forks, merges, and intersections, there genuinely isn’t a single correct future. With multiple modes, the model naturally spreads probability across different options, and the confidence head learned when to stay uncertain.</p>

<p>Soft-WTA turned out to be the difference between “multiple modes exist” and actually using them. Hard winner-take-all collapsed everything onto one trajectory. Once I switched to the temperature-scaled version, the modes stayed diverse but still got meaningful gradients.</p>

<h3 id="limitations">Limitations</h3>

<p>The raster is treated as frozen in time, so the model never reasons about moving agents beyond what’s captured in the single frame. That also means any “interaction modeling” is purely implicit and the CNN might pick up on nearby cars, but nothing explicitly tells the model how agents influence each other.</p>

<p>The fixed number of modes is also a bit inflexible. Six is sometimes too many (simple highway following) and sometimes not enough (busy urban intersections). And, like most datasets, this one has biases. The model struggles with rare edge cases like U-turns, emergency braking, simply because it hasn’t seen enough of them.</p>

<h3 id="potential-improvements">Potential Improvements</h3>

<p>A transformer-based architecture is probably the cleanest upgrade path. Models like Wayformer or SceneTransformer handle long-range structure better than CNN+MLP. Switching to vectorized map inputs (lane polylines, connectivity graphs) would let the model reason geometrically instead of relying on pixel-based approximations.</p>

<p>Another promising direction is goal conditioning. Predicting trajectories relative to plausible end goals like intersection exits. That tends to make the model’s outputs more structured and easier to interpret. Finally, there’s a lot left on the table with multi-agent prediction. Handling multiple agents jointly would go a long way toward more realistic interaction modeling. Even using a short raster “video” instead of a single frame would give the model a better sense of temporal context.</p>

<hr />

<h2 id="conclusion">Conclusion</h2>

<p>This project highlighted how inherently uncertain real driving behavior is. Vehicles do not follow fixed patterns. They respond to road geometry, evolving goals, and subtle scene cues. As the model began to incorporate these factors, its predictions became noticeably more realistic. There is still substantial room for improvement, particularly in modeling interactions between multiple agents rather than assuming a static environment. Even so, the work help build the architectural and design decisions behind trajectory prediction and shifted the process from trial-and-error to informed development. Given the limited training time, I am happy with the current model’s performance. I hope the analysis provides useful insight for anyone exploring this domain, and I look to improve this model over time.</p>

<h2 id="code-repository">Code Repository</h2>

<p><a href="https://github.com/albert97567/trajectory-prediction">https://github.com/albert97567/trajectory-prediction</a></p>

<h2 id="references">References</h2>

<p>[1] L5Kit Library Documentation. <a href="https://woven-planet.github.io/l5kit/">https://woven-planet.github.io/l5kit/</a></p>

<p>[2] Waymo Team. “VectorNet: Predicting behavior to help the Waymo Driver make better decisions.” <em>Waymo Blog, 2020</em>. <a href="https://blog.waymo.com/2020/05/vectornet.html">https://blog.waymo.com/2020/05/vectornet.html</a></p>

<p>[3] Woven Planet Level 5. “How to Build a Motion Prediction Model for Autonomous Vehicles.” <em>Medium, 2020</em>. <a href="https://medium.com/wovenplanetlevel5/how-to-build-a-motion-prediction-model-for-autonomous-vehicles-29f7f81f1580">https://medium.com/wovenplanetlevel5/how-to-build-a-motion-prediction-model-for-autonomous-vehicles-29f7f81f1580</a></p>

<p>[4] kool777. “Lyft Level5 EDA Training Inference.” <em>Kaggle Notebook</em>. <a href="https://www.kaggle.com/code/kool777/lyft-level5-eda-training-inference">https://www.kaggle.com/code/kool777/lyft-level5-eda-training-inference</a></p>

<hr />

<h2 id="acknowledgments">Acknowledgments</h2>

<p>I would like to thank the Lyft Level-5 team for releasing the motion prediction dataset and the l5kit library.</p>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>https://www.kaggle.com/c/lyft-motion-prediction-autonomous-vehicles/data <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Albert Le</name></author><summary type="html"><![CDATA[My 2 models predictions on scene 1679 from L5Kit Abstract Predicting the future trajectories of surrounding agents is a fundamental challenge in autonomous driving systems. In this project, I explore deep learning-based trajectory prediction using the Lyft Level-5 Motion Prediction dataset. I develop 2 models, a ResNet-based raster trajectory regressor, and a multimodal raster + agent-history fusion model capable of producing six future trajectory hypotheses with associated confidence scores. The final model achieves significant performance improvements in ADE, FDE, and Miss Rate metrics while producing interpretable, multimodal predictions essential for safe autonomous navigation.]]></summary></entry><entry><title type="html">Post Template</title><link href="http://localhost:4000/CS163-Projects-2025Fall/2024/01/01/team00-instruction-to-post.html" rel="alternate" type="text/html" title="Post Template" /><published>2024-01-01T00:00:00-08:00</published><updated>2024-01-01T00:00:00-08:00</updated><id>http://localhost:4000/CS163-Projects-2025Fall/2024/01/01/team00-instruction-to-post</id><content type="html" xml:base="http://localhost:4000/CS163-Projects-2025Fall/2024/01/01/team00-instruction-to-post.html"><![CDATA[<blockquote>
  <p>This block is a brief introduction of your project. You can put your abstract here or any headers you want the readers to know.</p>
</blockquote>

<!--more-->
<ul id="markdown-toc">
  <li><a href="#main-content" id="markdown-toc-main-content">Main Content</a></li>
  <li><a href="#basic-syntax" id="markdown-toc-basic-syntax">Basic Syntax</a>    <ul>
      <li><a href="#image" id="markdown-toc-image">Image</a></li>
      <li><a href="#table" id="markdown-toc-table">Table</a></li>
      <li><a href="#code-block" id="markdown-toc-code-block">Code Block</a></li>
      <li><a href="#formula" id="markdown-toc-formula">Formula</a></li>
      <li><a href="#more-markdown-syntax" id="markdown-toc-more-markdown-syntax">More Markdown Syntax</a></li>
    </ul>
  </li>
  <li><a href="#reference" id="markdown-toc-reference">Reference</a></li>
</ul>

<h2 id="main-content">Main Content</h2>
<p>Your survey starts here. You can refer to the <a href="https://github.com/lilianweng/lil-log/tree/master/_posts">source code</a> of <a href="https://lilianweng.github.io/lil-log/">lil’s blogs</a> for article structure ideas or Markdown syntax. We’ve provided a <a href="https://ucladeepvision.github.io/CS188-Projects-2022Winter/2017/06/21/an-overview-of-deep-learning.html">sample post</a> from Lilian Weng and you can find the source code <a href="https://raw.githubusercontent.com/UCLAdeepvision/CS188-Projects-2022Winter/main/_posts/2017-06-21-an-overview-of-deep-learning.md">here</a></p>

<h2 id="basic-syntax">Basic Syntax</h2>
<h3 id="image">Image</h3>
<p>Please create a folder with the name of your team id under /assets/images/, put all your images into the folder and reference the images in your main content.</p>

<p style="width: 400px; max-width: 100%;">You can add an image to your survey like this:
<img src="/CS163-Projects-2025Fall/assets/images/UCLAdeepvision/object_detection.png" alt="YOLO" /></p>
<p><em>Fig 1. YOLO: An object detection method in computer vision</em> [1].</p>

<p>Please cite the image if it is taken from other people’s work.</p>

<h3 id="table">Table</h3>
<p>Here is an example for creating tables, including alignment syntax.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left"> </th>
      <th style="text-align: center">column 1</th>
      <th style="text-align: right">column 2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">row1</td>
      <td style="text-align: center">Text</td>
      <td style="text-align: right">Text</td>
    </tr>
    <tr>
      <td style="text-align: left">row2</td>
      <td style="text-align: center">Text</td>
      <td style="text-align: right">Text</td>
    </tr>
  </tbody>
</table>

<h3 id="code-block">Code Block</h3>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># This is a sample code block
import torch
print (torch.__version__)
</code></pre></div></div>

<h3 id="formula">Formula</h3>
<p>Please use latex to generate formulas, such as:</p>

\[\tilde{\mathbf{z}}^{(t)}_i = \frac{\alpha \tilde{\mathbf{z}}^{(t-1)}_i + (1-\alpha) \mathbf{z}_i}{1-\alpha^t}\]

<p>or you can write in-text formula \(y = wx + b\).</p>

<h3 id="more-markdown-syntax">More Markdown Syntax</h3>
<p>You can find more Markdown syntax at <a href="https://www.markdownguide.org/basic-syntax/">this page</a>.</p>

<h2 id="reference">Reference</h2>
<p>Please make sure to cite properly in your work, for example:</p>

<p>[1] Redmon, Joseph, et al. “You only look once: Unified, real-time object detection.” <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em>. 2016.</p>

<hr />]]></content><author><name>UCLAdeepvision</name></author><summary type="html"><![CDATA[This block is a brief introduction of your project. You can put your abstract here or any headers you want the readers to know.]]></summary></entry></feed>